{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pinganGame1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/wangtianrui/Game/blob/master/pinganGame1.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bWOobN9RY3c8",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "d110aaa4-fa4c-4a2e-f64b-bd4dc6b6c430"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-30a5db9f-3d13-4b74-9e7c-d4da3d427cfe\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-30a5db9f-3d13-4b74-9e7c-d4da3d427cfe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wang_data.csv to wang_data.csv\n",
            "Saving wang_data_test.csv to wang_data_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v1prnCYoZX8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4ce019ee-8760-4aca-c271-62665429e49d"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  wang_data.csv\twang_data_test.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HFWbTRo3b3iD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28361
        },
        "outputId": "bcb14edd-2446-449c-de8c-3d294a95055a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "num_class = 2\n",
        "batch_size = 100\n",
        "train_path = r\"wang_data.csv\"\n",
        "test_path = r\"wang_data_test.csv\"\n",
        "learning_rate = 0.0000001\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "size = 37\n",
        "log_path = r\"./log/\"\n",
        "\n",
        "\n",
        "def readData(path):\n",
        "    whole_data = pd.read_csv(path, encoding='utf-8')\n",
        "    whole_data = whole_data.fillna(0)\n",
        "    whole_list = np.array(whole_data)\n",
        "    for i in range(len(whole_list)):\n",
        "        for temp in range(len(whole_list[i])):\n",
        "            if whole_list[i][temp] == \" \":\n",
        "                whole_list[i][temp] = 0\n",
        "    # print(\"转换前：\", whole_list)\n",
        "    whole_list = np.array(whole_list, dtype=\"float\")\n",
        "    # print(whole_list)\n",
        "    return whole_list\n",
        "\n",
        "\n",
        "def makeData(data, flag):\n",
        "    x = []\n",
        "    y = []\n",
        "    ran = []\n",
        "    # print(len(data))\n",
        "    # print(len(data[1480]))\n",
        "    # print(data)\n",
        "    if flag == \"train\":\n",
        "        for i in range(batch_size):\n",
        "            index = random.randint(0, 6384)\n",
        "            # print(\"test data len\", len(data))\n",
        "            row = data[index]\n",
        "            label = [int(row[37])]\n",
        "            y.append(label)\n",
        "            row = np.delete(row, 37)\n",
        "            x.append(row)\n",
        "            ran.append(index)\n",
        "    else:\n",
        "        for i in range(batch_size):\n",
        "            index = random.randint(0, 66)\n",
        "            # print(\"test data len\", len(data))\n",
        "            row = data[index]\n",
        "            label = [int(row[37])]\n",
        "            y.append(label)\n",
        "            row = np.delete(row, 37)\n",
        "            x.append(row)\n",
        "            ran.append(index)\n",
        "    # print(label)\n",
        "    # print(\"lenx:\",len(x))\n",
        "    # print(\"len x1:\",len(x[1]))\n",
        "    # x = tf.reshape(x, shape=[batch_size, size])\n",
        "    # label = tf.reshape(label, shape=[batch_size, 2])\n",
        "\n",
        "    return x, y, ran\n",
        "\n",
        "\n",
        "def getWeight(shape):\n",
        "    w = tf.truncated_normal(shape, 0.1)\n",
        "    return tf.Variable(w)\n",
        "\n",
        "\n",
        "def getBias(shape):\n",
        "    b = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(b)\n",
        "\n",
        "\n",
        "def fc(input, keep_prob):\n",
        "    fc1_w = getWeight([size, 128])\n",
        "    fc1_b = getBias([128])\n",
        "    fc1 = tf.nn.relu(tf.matmul(input, fc1_w) + fc1_b)\n",
        "    h_fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
        "    fc2_w = getWeight([128, 2])\n",
        "    fc2_b = getBias([2])\n",
        "    fc2 = tf.matmul(h_fc1_drop, fc2_w) + fc2_b\n",
        "\n",
        "    return fc2, fc1_w, fc2_w\n",
        "\n",
        "\n",
        "def cross_entropy(fc_result, label):\n",
        "    label = tf.one_hot(label, depth=num_class)\n",
        "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=fc_result, labels=label))\n",
        "\n",
        "\n",
        "def train():\n",
        "    x_ = tf.placeholder(shape=[batch_size, size], dtype=\"float\")\n",
        "    y_ = tf.placeholder(shape=[batch_size, 1], dtype=\"int32\")\n",
        "    keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
        "    logits, fc1, fc2 = fc(x_, keep_prob)\n",
        "    loss = cross_entropy(logits, y_)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    train_op = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess = tf.Session(config=config)\n",
        "    sess.run(init)\n",
        "    saver = tf.train.Saver(tf.global_variables())\n",
        "    whole_data = readData(train_path)\n",
        "    test_data = readData(test_path)\n",
        "    # whole_data = sess.run(read_data)\n",
        "    for i in range(3000000):\n",
        "        if i % 100 == 0:\n",
        "            x, y, indexs = makeData(whole_data, \"train\")\n",
        "            test_x, test_y, test_index = makeData(test_data, \"test\")\n",
        "            ss_x = StandardScaler()\n",
        "            ss_y = StandardScaler()\n",
        "\n",
        "            x = ss_x.fit_transform(x)\n",
        "            y = ss_y.fit_transform(y)\n",
        "            test_x = ss_x.transform(test_x)\n",
        "            test_y = ss_y.transform(test_y)\n",
        "\n",
        "            # x = tf.reshape(x, shape=[batch_size, size])\n",
        "            # x = tf.cast(x, dtype=tf.float32)\n",
        "            train_accuracy = sess.run(accuracy, feed_dict={x_: test_x, y_: test_y, keep_prob: 1})\n",
        "            lo = sess.run(loss, feed_dict={x_: x, y_: y, keep_prob: 1})\n",
        "            # f1w = sess.run(fc1, feed_dict={x_: x, y_: y, keep_prob: 1})\n",
        "            # f2w = sess.run(fc2, feed_dict={x_: x, y_: y, keep_prob: 1})\n",
        "            # print(\"f1:\",f1w,\"\\n\",\"f2:\",f2w)\n",
        "            print(\"step %d, train accuracy %g , loss %g\" % (i, train_accuracy, lo))\n",
        "            # print(indexs)\n",
        "        if i % 5000 == 0 and i != 0:\n",
        "            save_path = os.path.join(log_path, \"model.ckpt\")\n",
        "            saver.save(sess, save_path, global_step=i)\n",
        "\n",
        "        sess.run(train_op, feed_dict={x_: x, y_: y, keep_prob: 0.5})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, train accuracy 0.12 , loss 2779.43\n",
            "step 100, train accuracy 0.21 , loss 2402.67\n",
            "step 200, train accuracy 0.11 , loss 2761.96\n",
            "step 300, train accuracy 0.13 , loss 2513.55\n",
            "step 400, train accuracy 0.14 , loss 2019.63\n",
            "step 500, train accuracy 0.07 , loss 2752.37\n",
            "step 600, train accuracy 0.13 , loss 2520\n",
            "step 700, train accuracy 0.2 , loss 2378.62\n",
            "step 800, train accuracy 0.12 , loss 1979.97\n",
            "step 900, train accuracy 0.08 , loss 2432.3\n",
            "step 1000, train accuracy 0.12 , loss 2374.79\n",
            "step 1100, train accuracy 0.15 , loss 2658.12\n",
            "step 1200, train accuracy 0.22 , loss 1995.58\n",
            "step 1300, train accuracy 0.09 , loss 2516.21\n",
            "step 1400, train accuracy 0.08 , loss 2219.25\n",
            "step 1500, train accuracy 0.07 , loss 2013.54\n",
            "step 1600, train accuracy 0.21 , loss 1928.89\n",
            "step 1700, train accuracy 0.19 , loss 2396.27\n",
            "step 1800, train accuracy 0.13 , loss 1743.3\n",
            "step 1900, train accuracy 0.17 , loss 2025.44\n",
            "step 2000, train accuracy 0.13 , loss 1645.76\n",
            "step 2100, train accuracy 0.2 , loss 1902.69\n",
            "step 2200, train accuracy 0.29 , loss 1926.43\n",
            "step 2300, train accuracy 0.14 , loss 1637.05\n",
            "step 2400, train accuracy 0.26 , loss 1970.98\n",
            "step 2500, train accuracy 0.17 , loss 1741.13\n",
            "step 2600, train accuracy 0.16 , loss 2080.26\n",
            "step 2700, train accuracy 0.21 , loss 2048.84\n",
            "step 2800, train accuracy 0.21 , loss 1902.62\n",
            "step 2900, train accuracy 0.17 , loss 1869.06\n",
            "step 3000, train accuracy 0.22 , loss 2000.71\n",
            "step 3100, train accuracy 0.16 , loss 2050.17\n",
            "step 3200, train accuracy 0.26 , loss 2200.7\n",
            "step 3300, train accuracy 0.28 , loss 2418.72\n",
            "step 3400, train accuracy 0.13 , loss 1805.31\n",
            "step 3500, train accuracy 0.18 , loss 1873.82\n",
            "step 3600, train accuracy 0.26 , loss 2190.47\n",
            "step 3700, train accuracy 0.2 , loss 2079.82\n",
            "step 3800, train accuracy 0.15 , loss 2065.1\n",
            "step 3900, train accuracy 0.23 , loss 1819.52\n",
            "step 4000, train accuracy 0.15 , loss 1930.22\n",
            "step 4100, train accuracy 0.17 , loss 1780.58\n",
            "step 4200, train accuracy 0.16 , loss 1652.63\n",
            "step 4300, train accuracy 0.32 , loss 1560.07\n",
            "step 4400, train accuracy 0.23 , loss 1458.23\n",
            "step 4500, train accuracy 0.24 , loss 1514.84\n",
            "step 4600, train accuracy 0.21 , loss 1992.33\n",
            "step 4700, train accuracy 0.29 , loss 1769.69\n",
            "step 4800, train accuracy 0.33 , loss 1559.28\n",
            "step 4900, train accuracy 0.4 , loss 1901.9\n",
            "step 5000, train accuracy 0.25 , loss 1440.6\n",
            "step 5100, train accuracy 0.26 , loss 1773.82\n",
            "step 5200, train accuracy 0.29 , loss 1653.28\n",
            "step 5300, train accuracy 0.27 , loss 1287.9\n",
            "step 5400, train accuracy 0.46 , loss 1665.48\n",
            "step 5500, train accuracy 0.3 , loss 1381.32\n",
            "step 5600, train accuracy 0.31 , loss 1673.42\n",
            "step 5700, train accuracy 0.31 , loss 1766.82\n",
            "step 5800, train accuracy 0.32 , loss 1791.84\n",
            "step 5900, train accuracy 0.4 , loss 1606.87\n",
            "step 6000, train accuracy 0.28 , loss 1392.01\n",
            "step 6100, train accuracy 0.43 , loss 1588.61\n",
            "step 6200, train accuracy 0.42 , loss 1180.25\n",
            "step 6300, train accuracy 0.32 , loss 1152.64\n",
            "step 6400, train accuracy 0.27 , loss 1922.7\n",
            "step 6500, train accuracy 0.24 , loss 1065.88\n",
            "step 6600, train accuracy 0.34 , loss 1241.93\n",
            "step 6700, train accuracy 0.34 , loss 1525.77\n",
            "step 6800, train accuracy 0.37 , loss 1295.96\n",
            "step 6900, train accuracy 0.27 , loss 1341.98\n",
            "step 7000, train accuracy 0.32 , loss 1753.24\n",
            "step 7100, train accuracy 0.32 , loss 1406.22\n",
            "step 7200, train accuracy 0.3 , loss 1604.27\n",
            "step 7300, train accuracy 0.44 , loss 1524.95\n",
            "step 7400, train accuracy 0.31 , loss 1582.36\n",
            "step 7500, train accuracy 0.38 , loss 1739.06\n",
            "step 7600, train accuracy 0.26 , loss 1258.12\n",
            "step 7700, train accuracy 0.38 , loss 1228.49\n",
            "step 7800, train accuracy 0.44 , loss 1181.06\n",
            "step 7900, train accuracy 0.35 , loss 1368.49\n",
            "step 8000, train accuracy 0.5 , loss 462.738\n",
            "step 8100, train accuracy 0.38 , loss 1450.77\n",
            "step 8200, train accuracy 0.36 , loss 1324.79\n",
            "step 8300, train accuracy 0.46 , loss 1420.75\n",
            "step 8400, train accuracy 0.41 , loss 1666.77\n",
            "step 8500, train accuracy 0.34 , loss 1416.42\n",
            "step 8600, train accuracy 0.44 , loss 1409.64\n",
            "step 8700, train accuracy 0.44 , loss 333.309\n",
            "step 8800, train accuracy 0.34 , loss 1305.12\n",
            "step 8900, train accuracy 0.44 , loss 1417.91\n",
            "step 9000, train accuracy 0.43 , loss 1182.19\n",
            "step 9100, train accuracy 0.55 , loss 913.96\n",
            "step 9200, train accuracy 0.46 , loss 1128.52\n",
            "step 9300, train accuracy 0.48 , loss 1456.42\n",
            "step 9400, train accuracy 0.44 , loss 1234.53\n",
            "step 9500, train accuracy 0.41 , loss 1145.87\n",
            "step 9600, train accuracy 0.43 , loss 1299.62\n",
            "step 9700, train accuracy 0.55 , loss 1183.6\n",
            "step 9800, train accuracy 0.57 , loss 1625.32\n",
            "step 9900, train accuracy 0.47 , loss 1218.9\n",
            "step 10000, train accuracy 0.52 , loss 1610.6\n",
            "step 10100, train accuracy 0.47 , loss 1558.6\n",
            "step 10200, train accuracy 0.38 , loss 1009.14\n",
            "step 10300, train accuracy 0.35 , loss 1332.36\n",
            "step 10400, train accuracy 0.49 , loss 1097.55\n",
            "step 10500, train accuracy 0.41 , loss 1442.18\n",
            "step 10600, train accuracy 0.45 , loss 932.03\n",
            "step 10700, train accuracy 0.3 , loss 1177.47\n",
            "step 10800, train accuracy 0.61 , loss 1051.74\n",
            "step 10900, train accuracy 0.51 , loss 742.639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 11000, train accuracy 0.49 , loss 1387.63\n",
            "step 11100, train accuracy 0.43 , loss 920.22\n",
            "step 11200, train accuracy 0.46 , loss 1499.28\n",
            "step 11300, train accuracy 0.42 , loss 471.136\n",
            "step 11400, train accuracy 0.42 , loss 1080.43\n",
            "step 11500, train accuracy 0.5 , loss 1334.25\n",
            "step 11600, train accuracy 0.35 , loss 628.705\n",
            "step 11700, train accuracy 0.47 , loss 1206.68\n",
            "step 11800, train accuracy 0.48 , loss 1012.4\n",
            "step 11900, train accuracy 0.54 , loss 1048.03\n",
            "step 12000, train accuracy 0.54 , loss 1456.52\n",
            "step 12100, train accuracy 0.47 , loss 1453.94\n",
            "step 12200, train accuracy 0.32 , loss 962.301\n",
            "step 12300, train accuracy 0.33 , loss 845.408\n",
            "step 12400, train accuracy 0.55 , loss 713.52\n",
            "step 12500, train accuracy 0.56 , loss 999.848\n",
            "step 12600, train accuracy 0.38 , loss 713.867\n",
            "step 12700, train accuracy 0.44 , loss 1654.33\n",
            "step 12800, train accuracy 0.37 , loss 1072.73\n",
            "step 12900, train accuracy 0.47 , loss 1297.01\n",
            "step 13000, train accuracy 0.49 , loss 1453.69\n",
            "step 13100, train accuracy 0.57 , loss 1312.36\n",
            "step 13200, train accuracy 0.37 , loss 744.859\n",
            "step 13300, train accuracy 0.52 , loss 1222.16\n",
            "step 13400, train accuracy 0.5 , loss 1432.9\n",
            "step 13500, train accuracy 0.5 , loss 1024.58\n",
            "step 13600, train accuracy 0.57 , loss 1093.1\n",
            "step 13700, train accuracy 0.45 , loss 975.328\n",
            "step 13800, train accuracy 0.62 , loss 1443.02\n",
            "step 13900, train accuracy 0.48 , loss 1393.46\n",
            "step 14000, train accuracy 0.46 , loss 1448.72\n",
            "step 14100, train accuracy 0.36 , loss 1689.8\n",
            "step 14200, train accuracy 0.64 , loss 539.099\n",
            "step 14300, train accuracy 0.44 , loss 588.933\n",
            "step 14400, train accuracy 0.46 , loss 1449.85\n",
            "step 14500, train accuracy 0.5 , loss 1266.31\n",
            "step 14600, train accuracy 0.41 , loss 963.939\n",
            "step 14700, train accuracy 0.54 , loss 520.233\n",
            "step 14800, train accuracy 0.55 , loss 925.733\n",
            "step 14900, train accuracy 0.47 , loss 881.957\n",
            "step 15000, train accuracy 0.42 , loss 685.243\n",
            "step 15100, train accuracy 0.54 , loss 1935.22\n",
            "step 15200, train accuracy 0.59 , loss 1093.83\n",
            "step 15300, train accuracy 0.7 , loss 1326.59\n",
            "step 15400, train accuracy 0.52 , loss 1603.73\n",
            "step 15500, train accuracy 0.45 , loss 1215.37\n",
            "step 15600, train accuracy 0.56 , loss 323.429\n",
            "step 15700, train accuracy 0.51 , loss 1003.24\n",
            "step 15800, train accuracy 0.4 , loss 1191.16\n",
            "step 15900, train accuracy 0.5 , loss 1518.67\n",
            "step 16000, train accuracy 0.58 , loss 617.141\n",
            "step 16100, train accuracy 0.44 , loss 1098.48\n",
            "step 16200, train accuracy 0.61 , loss 1377.23\n",
            "step 16300, train accuracy 0.57 , loss 652.174\n",
            "step 16400, train accuracy 0.5 , loss 1431.73\n",
            "step 16500, train accuracy 0.49 , loss 1037.69\n",
            "step 16600, train accuracy 0.56 , loss 1523.98\n",
            "step 16700, train accuracy 0.44 , loss 1188.36\n",
            "step 16800, train accuracy 0.41 , loss 890.502\n",
            "step 16900, train accuracy 0.59 , loss 643.532\n",
            "step 17000, train accuracy 0.45 , loss 1455.45\n",
            "step 17100, train accuracy 0.55 , loss 837.111\n",
            "step 17200, train accuracy 0.54 , loss 1399.5\n",
            "step 17300, train accuracy 0.64 , loss 820.496\n",
            "step 17400, train accuracy 0.52 , loss 598.386\n",
            "step 17500, train accuracy 0.54 , loss 699.191\n",
            "step 17600, train accuracy 0.6 , loss 1056.54\n",
            "step 17700, train accuracy 0.49 , loss 806.371\n",
            "step 17800, train accuracy 0.53 , loss 1173.57\n",
            "step 17900, train accuracy 0.52 , loss 574.826\n",
            "step 18000, train accuracy 0.49 , loss 1337.19\n",
            "step 18100, train accuracy 0.56 , loss 1001.48\n",
            "step 18200, train accuracy 0.52 , loss 642.174\n",
            "step 18300, train accuracy 0.62 , loss 1017.7\n",
            "step 18400, train accuracy 0.49 , loss 1248.96\n",
            "step 18500, train accuracy 0.56 , loss 1250.3\n",
            "step 18600, train accuracy 0.56 , loss 598.06\n",
            "step 18700, train accuracy 0.53 , loss 781.705\n",
            "step 18800, train accuracy 0.52 , loss 1221.44\n",
            "step 18900, train accuracy 0.46 , loss 788.165\n",
            "step 19000, train accuracy 0.65 , loss 1112.1\n",
            "step 19100, train accuracy 0.56 , loss 996.29\n",
            "step 19200, train accuracy 0.53 , loss 1069.22\n",
            "step 19300, train accuracy 0.59 , loss 741.565\n",
            "step 19400, train accuracy 0.57 , loss 731.415\n",
            "step 19500, train accuracy 0.54 , loss 676.069\n",
            "step 19600, train accuracy 0.53 , loss 980.663\n",
            "step 19700, train accuracy 0.59 , loss 766.018\n",
            "step 19800, train accuracy 0.53 , loss 784.712\n",
            "step 19900, train accuracy 0.52 , loss 814.822\n",
            "step 20000, train accuracy 0.72 , loss 447.341\n",
            "step 20100, train accuracy 0.49 , loss 1009.02\n",
            "step 20200, train accuracy 0.63 , loss 708.698\n",
            "step 20300, train accuracy 0.7 , loss 534.277\n",
            "step 20400, train accuracy 0.46 , loss 885.196\n",
            "step 20500, train accuracy 0.58 , loss 856.829\n",
            "step 20600, train accuracy 0.6 , loss 908.107\n",
            "step 20700, train accuracy 0.49 , loss 1309.65\n",
            "step 20800, train accuracy 0.6 , loss 550.795\n",
            "step 20900, train accuracy 0.54 , loss 915.605\n",
            "step 21000, train accuracy 0.47 , loss 697.097\n",
            "step 21100, train accuracy 0.6 , loss 596.547\n",
            "step 21200, train accuracy 0.56 , loss 1289.4\n",
            "step 21300, train accuracy 0.49 , loss 611.429\n",
            "step 21400, train accuracy 0.49 , loss 715.338\n",
            "step 21500, train accuracy 0.64 , loss 693.826\n",
            "step 21600, train accuracy 0.66 , loss 977.152\n",
            "step 21700, train accuracy 0.5 , loss 1145.97\n",
            "step 21800, train accuracy 0.69 , loss 1058.72\n",
            "step 21900, train accuracy 0.58 , loss 938.585\n",
            "step 22000, train accuracy 0.58 , loss 547.081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 22100, train accuracy 0.56 , loss 883.102\n",
            "step 22200, train accuracy 0.59 , loss 699.891\n",
            "step 22300, train accuracy 0.49 , loss 1278.8\n",
            "step 22400, train accuracy 0.54 , loss 652.624\n",
            "step 22500, train accuracy 0.53 , loss 541.466\n",
            "step 22600, train accuracy 0.65 , loss 966.145\n",
            "step 22700, train accuracy 0.61 , loss 568.312\n",
            "step 22800, train accuracy 0.47 , loss 764.411\n",
            "step 22900, train accuracy 0.55 , loss 667.622\n",
            "step 23000, train accuracy 0.6 , loss 828.387\n",
            "step 23100, train accuracy 0.46 , loss 543.044\n",
            "step 23200, train accuracy 0.59 , loss 1313.88\n",
            "step 23300, train accuracy 0.53 , loss 690.661\n",
            "step 23400, train accuracy 0.59 , loss 815.504\n",
            "step 23500, train accuracy 0.36 , loss 943.646\n",
            "step 23600, train accuracy 0.55 , loss 861.481\n",
            "step 23700, train accuracy 0.54 , loss 607.913\n",
            "step 23800, train accuracy 0.53 , loss 760.895\n",
            "step 23900, train accuracy 0.69 , loss 1111.04\n",
            "step 24000, train accuracy 0.63 , loss 1144.64\n",
            "step 24100, train accuracy 0.54 , loss 663.043\n",
            "step 24200, train accuracy 0.66 , loss 583.388\n",
            "step 24300, train accuracy 0.61 , loss 1200.33\n",
            "step 24400, train accuracy 0.64 , loss 736.648\n",
            "step 24500, train accuracy 0.64 , loss 443.074\n",
            "step 24600, train accuracy 0.62 , loss 519.348\n",
            "step 24700, train accuracy 0.68 , loss 690.658\n",
            "step 24800, train accuracy 0.55 , loss 1125.99\n",
            "step 24900, train accuracy 0.66 , loss 1280.73\n",
            "step 25000, train accuracy 0.51 , loss 1220.46\n",
            "step 25100, train accuracy 0.6 , loss 891.132\n",
            "step 25200, train accuracy 0.54 , loss 628.542\n",
            "step 25300, train accuracy 0.6 , loss 1131.35\n",
            "step 25400, train accuracy 0.66 , loss 824.214\n",
            "step 25500, train accuracy 0.66 , loss 696.194\n",
            "step 25600, train accuracy 0.66 , loss 976.015\n",
            "step 25700, train accuracy 0.6 , loss 779.38\n",
            "step 25800, train accuracy 0.56 , loss 661.773\n",
            "step 25900, train accuracy 0.62 , loss 1053.65\n",
            "step 26000, train accuracy 0.42 , loss 1261.65\n",
            "step 26100, train accuracy 0.56 , loss 510.975\n",
            "step 26200, train accuracy 0.65 , loss 312.848\n",
            "step 26300, train accuracy 0.69 , loss 1037.46\n",
            "step 26400, train accuracy 0.59 , loss 979.975\n",
            "step 26500, train accuracy 0.53 , loss 555.927\n",
            "step 26600, train accuracy 0.75 , loss 553.123\n",
            "step 26700, train accuracy 0.59 , loss 1051.28\n",
            "step 26800, train accuracy 0.68 , loss 1222.74\n",
            "step 26900, train accuracy 0.64 , loss 628.301\n",
            "step 27000, train accuracy 0.66 , loss 754.83\n",
            "step 27100, train accuracy 0.56 , loss 544.597\n",
            "step 27200, train accuracy 0.63 , loss 483.076\n",
            "step 27300, train accuracy 0.69 , loss 403.9\n",
            "step 27400, train accuracy 0.51 , loss 521.504\n",
            "step 27500, train accuracy 0.6 , loss 1191.03\n",
            "step 27600, train accuracy 0.59 , loss 455.784\n",
            "step 27700, train accuracy 0.65 , loss 242.38\n",
            "step 27800, train accuracy 0.61 , loss 389.803\n",
            "step 27900, train accuracy 0.63 , loss 1007.96\n",
            "step 28000, train accuracy 0.55 , loss 1223.75\n",
            "step 28100, train accuracy 0.54 , loss 1285.2\n",
            "step 28200, train accuracy 0.7 , loss 544.505\n",
            "step 28300, train accuracy 0.7 , loss 468.758\n",
            "step 28400, train accuracy 0.69 , loss 793.498\n",
            "step 28500, train accuracy 0.68 , loss 1053.45\n",
            "step 28600, train accuracy 0.61 , loss 377.636\n",
            "step 28700, train accuracy 0.67 , loss 898.67\n",
            "step 28800, train accuracy 0.66 , loss 621.151\n",
            "step 28900, train accuracy 0.64 , loss 1425.02\n",
            "step 29000, train accuracy 0.67 , loss 421.597\n",
            "step 29100, train accuracy 0.57 , loss 392.679\n",
            "step 29200, train accuracy 0.52 , loss 903.456\n",
            "step 29300, train accuracy 0.77 , loss 548.232\n",
            "step 29400, train accuracy 0.65 , loss 959.634\n",
            "step 29500, train accuracy 0.58 , loss 488.156\n",
            "step 29600, train accuracy 0.65 , loss 369.635\n",
            "step 29700, train accuracy 0.7 , loss 568.882\n",
            "step 29800, train accuracy 0.68 , loss 1272.13\n",
            "step 29900, train accuracy 0.67 , loss 1256.12\n",
            "step 30000, train accuracy 0.7 , loss 763.342\n",
            "step 30100, train accuracy 0.64 , loss 391.922\n",
            "step 30200, train accuracy 0.64 , loss 465.601\n",
            "step 30300, train accuracy 0.65 , loss 908.169\n",
            "step 30400, train accuracy 0.67 , loss 1365.62\n",
            "step 30500, train accuracy 0.76 , loss 418.263\n",
            "step 30600, train accuracy 0.66 , loss 425.89\n",
            "step 30700, train accuracy 0.68 , loss 406.283\n",
            "step 30800, train accuracy 0.64 , loss 448.83\n",
            "step 30900, train accuracy 0.68 , loss 1150.04\n",
            "step 31000, train accuracy 0.49 , loss 370.944\n",
            "step 31100, train accuracy 0.66 , loss 1277.26\n",
            "step 31200, train accuracy 0.7 , loss 1161.28\n",
            "step 31300, train accuracy 0.65 , loss 304.355\n",
            "step 31400, train accuracy 0.72 , loss 1148.52\n",
            "step 31500, train accuracy 0.65 , loss 799.122\n",
            "step 31600, train accuracy 0.63 , loss 1022.37\n",
            "step 31700, train accuracy 0.76 , loss 476.01\n",
            "step 31800, train accuracy 0.56 , loss 364.988\n",
            "step 31900, train accuracy 0.6 , loss 1263.7\n",
            "step 32000, train accuracy 0.52 , loss 865.127\n",
            "step 32100, train accuracy 0.7 , loss 455.173\n",
            "step 32200, train accuracy 0.62 , loss 292.4\n",
            "step 32300, train accuracy 0.73 , loss 363.538\n",
            "step 32400, train accuracy 0.65 , loss 339.735\n",
            "step 32500, train accuracy 0.79 , loss 729.382\n",
            "step 32600, train accuracy 0.57 , loss 456.353\n",
            "step 32700, train accuracy 0.7 , loss 637.451\n",
            "step 32800, train accuracy 0.61 , loss 445.062\n",
            "step 32900, train accuracy 0.6 , loss 434.008\n",
            "step 33000, train accuracy 0.68 , loss 861.583\n",
            "step 33100, train accuracy 0.63 , loss 1169.31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 33200, train accuracy 0.63 , loss 353.465\n",
            "step 33300, train accuracy 0.67 , loss 1410.94\n",
            "step 33400, train accuracy 0.73 , loss 1205.67\n",
            "step 33500, train accuracy 0.61 , loss 477.425\n",
            "step 33600, train accuracy 0.63 , loss 945.964\n",
            "step 33700, train accuracy 0.6 , loss 948.043\n",
            "step 33800, train accuracy 0.69 , loss 562.641\n",
            "step 33900, train accuracy 0.63 , loss 349.193\n",
            "step 34000, train accuracy 0.64 , loss 1110.74\n",
            "step 34100, train accuracy 0.78 , loss 416.421\n",
            "step 34200, train accuracy 0.78 , loss 319.321\n",
            "step 34300, train accuracy 0.54 , loss 466.045\n",
            "step 34400, train accuracy 0.65 , loss 318.167\n",
            "step 34500, train accuracy 0.68 , loss 1256.47\n",
            "step 34600, train accuracy 0.65 , loss 336.565\n",
            "step 34700, train accuracy 0.66 , loss 521.044\n",
            "step 34800, train accuracy 0.67 , loss 259.534\n",
            "step 34900, train accuracy 0.65 , loss 1069.14\n",
            "step 35000, train accuracy 0.58 , loss 303.142\n",
            "step 35100, train accuracy 0.56 , loss 196.392\n",
            "step 35200, train accuracy 0.71 , loss 505.294\n",
            "step 35300, train accuracy 0.6 , loss 283.839\n",
            "step 35400, train accuracy 0.64 , loss 325.755\n",
            "step 35500, train accuracy 0.72 , loss 823.192\n",
            "step 35600, train accuracy 0.6 , loss 482.608\n",
            "step 35700, train accuracy 0.64 , loss 1054.74\n",
            "step 35800, train accuracy 0.57 , loss 257.94\n",
            "step 35900, train accuracy 0.66 , loss 357.042\n",
            "step 36000, train accuracy 0.73 , loss 428.548\n",
            "step 36100, train accuracy 0.76 , loss 1285.96\n",
            "step 36200, train accuracy 0.65 , loss 266.125\n",
            "step 36300, train accuracy 0.61 , loss 295.749\n",
            "step 36400, train accuracy 0.64 , loss 1165.25\n",
            "step 36500, train accuracy 0.62 , loss 408.262\n",
            "step 36600, train accuracy 0.74 , loss 279.604\n",
            "step 36700, train accuracy 0.58 , loss 320.29\n",
            "step 36800, train accuracy 0.78 , loss 457.554\n",
            "step 36900, train accuracy 0.75 , loss 1106.39\n",
            "step 37000, train accuracy 0.78 , loss 316.055\n",
            "step 37100, train accuracy 0.77 , loss 413.326\n",
            "step 37200, train accuracy 0.64 , loss 333.202\n",
            "step 37300, train accuracy 0.6 , loss 437.668\n",
            "step 37400, train accuracy 0.78 , loss 610.668\n",
            "step 37500, train accuracy 0.71 , loss 1080.61\n",
            "step 37600, train accuracy 0.57 , loss 1070.34\n",
            "step 37700, train accuracy 0.76 , loss 340.992\n",
            "step 37800, train accuracy 0.74 , loss 368.598\n",
            "step 37900, train accuracy 0.67 , loss 247.765\n",
            "step 38000, train accuracy 0.74 , loss 1289.68\n",
            "step 38100, train accuracy 0.64 , loss 187.241\n",
            "step 38200, train accuracy 0.71 , loss 298.381\n",
            "step 38300, train accuracy 0.83 , loss 416.133\n",
            "step 38400, train accuracy 0.73 , loss 206.85\n",
            "step 38500, train accuracy 0.8 , loss 1236.43\n",
            "step 38600, train accuracy 0.57 , loss 959.42\n",
            "step 38700, train accuracy 0.61 , loss 1178.92\n",
            "step 38800, train accuracy 0.82 , loss 1644.79\n",
            "step 38900, train accuracy 0.7 , loss 1284.07\n",
            "step 39000, train accuracy 0.78 , loss 328.704\n",
            "step 39100, train accuracy 0.6 , loss 1265.74\n",
            "step 39200, train accuracy 0.81 , loss 428.396\n",
            "step 39300, train accuracy 0.7 , loss 322.492\n",
            "step 39400, train accuracy 0.8 , loss 96.4309\n",
            "step 39500, train accuracy 0.77 , loss 1398.36\n",
            "step 39600, train accuracy 0.8 , loss 369.025\n",
            "step 39700, train accuracy 0.65 , loss 153.725\n",
            "step 39800, train accuracy 0.69 , loss 269.832\n",
            "step 39900, train accuracy 0.8 , loss 977.743\n",
            "step 40000, train accuracy 0.81 , loss 1252.52\n",
            "step 40100, train accuracy 0.75 , loss 360.245\n",
            "step 40200, train accuracy 0.66 , loss 1429\n",
            "step 40300, train accuracy 0.81 , loss 1012.1\n",
            "step 40400, train accuracy 0.67 , loss 294.007\n",
            "step 40500, train accuracy 0.73 , loss 219.116\n",
            "step 40600, train accuracy 0.74 , loss 1005.92\n",
            "step 40700, train accuracy 0.77 , loss 404.941\n",
            "step 40800, train accuracy 0.69 , loss 270.856\n",
            "step 40900, train accuracy 0.64 , loss 1378.97\n",
            "step 41000, train accuracy 0.66 , loss 426.362\n",
            "step 41100, train accuracy 0.81 , loss 974.992\n",
            "step 41200, train accuracy 0.77 , loss 969.303\n",
            "step 41300, train accuracy 0.75 , loss 245.829\n",
            "step 41400, train accuracy 0.74 , loss 1193.36\n",
            "step 41500, train accuracy 0.74 , loss 1082.67\n",
            "step 41600, train accuracy 0.73 , loss 249.927\n",
            "step 41700, train accuracy 0.67 , loss 544.613\n",
            "step 41800, train accuracy 0.71 , loss 316.774\n",
            "step 41900, train accuracy 0.72 , loss 1131.31\n",
            "step 42000, train accuracy 0.74 , loss 264.678\n",
            "step 42100, train accuracy 0.63 , loss 1098.29\n",
            "step 42200, train accuracy 0.73 , loss 1395.88\n",
            "step 42300, train accuracy 0.63 , loss 953.656\n",
            "step 42400, train accuracy 0.66 , loss 1403.18\n",
            "step 42500, train accuracy 0.67 , loss 1325.81\n",
            "step 42600, train accuracy 0.63 , loss 377.299\n",
            "step 42700, train accuracy 0.67 , loss 1090.66\n",
            "step 42800, train accuracy 0.64 , loss 1241.44\n",
            "step 42900, train accuracy 0.78 , loss 1162.12\n",
            "step 43000, train accuracy 0.71 , loss 286.021\n",
            "step 43100, train accuracy 0.7 , loss 417.867\n",
            "step 43200, train accuracy 0.71 , loss 1119.43\n",
            "step 43300, train accuracy 0.76 , loss 611.583\n",
            "step 43400, train accuracy 0.74 , loss 467.98\n",
            "step 43500, train accuracy 0.65 , loss 417.56\n",
            "step 43600, train accuracy 0.76 , loss 248.347\n",
            "step 43700, train accuracy 0.69 , loss 414.663\n",
            "step 43800, train accuracy 0.78 , loss 541.104\n",
            "step 43900, train accuracy 0.77 , loss 916.581\n",
            "step 44000, train accuracy 0.76 , loss 459.119\n",
            "step 44100, train accuracy 0.57 , loss 219.041\n",
            "step 44200, train accuracy 0.71 , loss 285.401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 44300, train accuracy 0.73 , loss 231.439\n",
            "step 44400, train accuracy 0.77 , loss 984.981\n",
            "step 44500, train accuracy 0.62 , loss 990.386\n",
            "step 44600, train accuracy 0.72 , loss 290.09\n",
            "step 44700, train accuracy 0.65 , loss 238.929\n",
            "step 44800, train accuracy 0.74 , loss 1055.49\n",
            "step 44900, train accuracy 0.67 , loss 206.561\n",
            "step 45000, train accuracy 0.58 , loss 1174.78\n",
            "step 45100, train accuracy 0.76 , loss 948.54\n",
            "step 45200, train accuracy 0.7 , loss 532.212\n",
            "step 45300, train accuracy 0.81 , loss 1223.44\n",
            "step 45400, train accuracy 0.77 , loss 1081.83\n",
            "step 45500, train accuracy 0.65 , loss 1006.78\n",
            "step 45600, train accuracy 0.66 , loss 186.931\n",
            "step 45700, train accuracy 0.59 , loss 325.195\n",
            "step 45800, train accuracy 0.8 , loss 1069.27\n",
            "step 45900, train accuracy 0.66 , loss 212.947\n",
            "step 46000, train accuracy 0.72 , loss 358.876\n",
            "step 46100, train accuracy 0.69 , loss 163.636\n",
            "step 46200, train accuracy 0.66 , loss 843.715\n",
            "step 46300, train accuracy 0.77 , loss 253.41\n",
            "step 46400, train accuracy 0.71 , loss 161.223\n",
            "step 46500, train accuracy 0.78 , loss 286.856\n",
            "step 46600, train accuracy 0.75 , loss 321.609\n",
            "step 46700, train accuracy 0.81 , loss 1502.88\n",
            "step 46800, train accuracy 0.74 , loss 345.625\n",
            "step 46900, train accuracy 0.73 , loss 228.484\n",
            "step 47000, train accuracy 0.8 , loss 361.387\n",
            "step 47100, train accuracy 0.77 , loss 632.129\n",
            "step 47200, train accuracy 0.78 , loss 1147.35\n",
            "step 47300, train accuracy 0.7 , loss 1063.64\n",
            "step 47400, train accuracy 0.7 , loss 1143.38\n",
            "step 47500, train accuracy 0.65 , loss 312.612\n",
            "step 47600, train accuracy 0.62 , loss 306.035\n",
            "step 47700, train accuracy 0.67 , loss 1086.31\n",
            "step 47800, train accuracy 0.76 , loss 283.815\n",
            "step 47900, train accuracy 0.75 , loss 1218.49\n",
            "step 48000, train accuracy 0.73 , loss 1071.36\n",
            "step 48100, train accuracy 0.66 , loss 1074.59\n",
            "step 48200, train accuracy 0.63 , loss 314.891\n",
            "step 48300, train accuracy 0.56 , loss 1213.61\n",
            "step 48400, train accuracy 0.79 , loss 931.244\n",
            "step 48500, train accuracy 0.73 , loss 328.599\n",
            "step 48600, train accuracy 0.65 , loss 494.186\n",
            "step 48700, train accuracy 0.67 , loss 1520.35\n",
            "step 48800, train accuracy 0.76 , loss 1022.74\n",
            "step 48900, train accuracy 0.79 , loss 1023.04\n",
            "step 49000, train accuracy 0.8 , loss 270.503\n",
            "step 49100, train accuracy 0.71 , loss 1155.66\n",
            "step 49200, train accuracy 0.69 , loss 350.048\n",
            "step 49300, train accuracy 0.73 , loss 1008.61\n",
            "step 49400, train accuracy 0.57 , loss 1236.55\n",
            "step 49500, train accuracy 0.68 , loss 1239.89\n",
            "step 49600, train accuracy 0.74 , loss 319.788\n",
            "step 49700, train accuracy 0.77 , loss 312.331\n",
            "step 49800, train accuracy 0.63 , loss 240.36\n",
            "step 49900, train accuracy 0.68 , loss 1003.7\n",
            "step 50000, train accuracy 0.76 , loss 291.58\n",
            "step 50100, train accuracy 0.65 , loss 1224.59\n",
            "step 50200, train accuracy 0.59 , loss 195.451\n",
            "step 50300, train accuracy 0.79 , loss 375.974\n",
            "step 50400, train accuracy 0.6 , loss 347.004\n",
            "step 50500, train accuracy 0.72 , loss 989.587\n",
            "step 50600, train accuracy 0.8 , loss 920.346\n",
            "step 50700, train accuracy 0.75 , loss 1335.56\n",
            "step 50800, train accuracy 0.63 , loss 423.892\n",
            "step 50900, train accuracy 0.75 , loss 1110.7\n",
            "step 51000, train accuracy 0.65 , loss 947.879\n",
            "step 51100, train accuracy 0.68 , loss 1097.78\n",
            "step 51200, train accuracy 0.69 , loss 274.629\n",
            "step 51300, train accuracy 0.69 , loss 1000.76\n",
            "step 51400, train accuracy 0.72 , loss 436.509\n",
            "step 51500, train accuracy 0.62 , loss 329.432\n",
            "step 51600, train accuracy 0.68 , loss 1494.14\n",
            "step 51700, train accuracy 0.62 , loss 934.935\n",
            "step 51800, train accuracy 0.76 , loss 396.251\n",
            "step 51900, train accuracy 0.61 , loss 1100\n",
            "step 52000, train accuracy 0.66 , loss 1031.32\n",
            "step 52100, train accuracy 0.77 , loss 267.904\n",
            "step 52200, train accuracy 0.82 , loss 1340.51\n",
            "step 52300, train accuracy 0.65 , loss 297.782\n",
            "step 52400, train accuracy 0.7 , loss 1308.1\n",
            "step 52500, train accuracy 0.61 , loss 1096.05\n",
            "step 52600, train accuracy 0.65 , loss 376.795\n",
            "step 52700, train accuracy 0.74 , loss 284.904\n",
            "step 52800, train accuracy 0.71 , loss 976.664\n",
            "step 52900, train accuracy 0.59 , loss 349.075\n",
            "step 53000, train accuracy 0.68 , loss 276.572\n",
            "step 53100, train accuracy 0.67 , loss 231.829\n",
            "step 53200, train accuracy 0.61 , loss 311.388\n",
            "step 53300, train accuracy 0.63 , loss 359.125\n",
            "step 53400, train accuracy 0.64 , loss 1047.11\n",
            "step 53500, train accuracy 0.7 , loss 1062.16\n",
            "step 53600, train accuracy 0.72 , loss 1006.64\n",
            "step 53700, train accuracy 0.73 , loss 1071.16\n",
            "step 53800, train accuracy 0.62 , loss 359.671\n",
            "step 53900, train accuracy 0.66 , loss 221.488\n",
            "step 54000, train accuracy 0.74 , loss 1204.06\n",
            "step 54100, train accuracy 0.6 , loss 1093.54\n",
            "step 54200, train accuracy 0.71 , loss 200.553\n",
            "step 54300, train accuracy 0.67 , loss 964.384\n",
            "step 54400, train accuracy 0.58 , loss 978.023\n",
            "step 54500, train accuracy 0.71 , loss 211.26\n",
            "step 54600, train accuracy 0.59 , loss 1070.19\n",
            "step 54700, train accuracy 0.65 , loss 310.116\n",
            "step 54800, train accuracy 0.68 , loss 1009.09\n",
            "step 54900, train accuracy 0.75 , loss 276.928\n",
            "step 55000, train accuracy 0.63 , loss 208.19\n",
            "step 55100, train accuracy 0.77 , loss 896.049\n",
            "step 55200, train accuracy 0.7 , loss 254.518\n",
            "step 55300, train accuracy 0.81 , loss 404.992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 55400, train accuracy 0.7 , loss 1101.29\n",
            "step 55500, train accuracy 0.64 , loss 339.666\n",
            "step 55600, train accuracy 0.7 , loss 302.005\n",
            "step 55700, train accuracy 0.78 , loss 1065.98\n",
            "step 55800, train accuracy 0.67 , loss 379.594\n",
            "step 55900, train accuracy 0.68 , loss 1109.14\n",
            "step 56000, train accuracy 0.7 , loss 1148.1\n",
            "step 56100, train accuracy 0.66 , loss 1064.21\n",
            "step 56200, train accuracy 0.69 , loss 899.255\n",
            "step 56300, train accuracy 0.72 , loss 1095.4\n",
            "step 56400, train accuracy 0.7 , loss 163.841\n",
            "step 56500, train accuracy 0.74 , loss 359.008\n",
            "step 56600, train accuracy 0.7 , loss 228.241\n",
            "step 56700, train accuracy 0.77 , loss 211.202\n",
            "step 56800, train accuracy 0.68 , loss 175.565\n",
            "step 56900, train accuracy 0.68 , loss 255.114\n",
            "step 57000, train accuracy 0.73 , loss 823.951\n",
            "step 57100, train accuracy 0.65 , loss 177.844\n",
            "step 57200, train accuracy 0.7 , loss 1089.5\n",
            "step 57300, train accuracy 0.76 , loss 972.502\n",
            "step 57400, train accuracy 0.7 , loss 259.412\n",
            "step 57500, train accuracy 0.71 , loss 1025.05\n",
            "step 57600, train accuracy 0.77 , loss 912.014\n",
            "step 57700, train accuracy 0.74 , loss 244.849\n",
            "step 57800, train accuracy 0.68 , loss 211.007\n",
            "step 57900, train accuracy 0.61 , loss 287.54\n",
            "step 58000, train accuracy 0.72 , loss 190.685\n",
            "step 58100, train accuracy 0.7 , loss 986.024\n",
            "step 58200, train accuracy 0.75 , loss 186.89\n",
            "step 58300, train accuracy 0.77 , loss 945.765\n",
            "step 58400, train accuracy 0.78 , loss 420.168\n",
            "step 58500, train accuracy 0.73 , loss 370.033\n",
            "step 58600, train accuracy 0.69 , loss 1217.93\n",
            "step 58700, train accuracy 0.76 , loss 338.684\n",
            "step 58800, train accuracy 0.7 , loss 1087.83\n",
            "step 58900, train accuracy 0.68 , loss 646.995\n",
            "step 59000, train accuracy 0.68 , loss 1279.67\n",
            "step 59100, train accuracy 0.67 , loss 388.981\n",
            "step 59200, train accuracy 0.59 , loss 893.951\n",
            "step 59300, train accuracy 0.64 , loss 1051.7\n",
            "step 59400, train accuracy 0.73 , loss 224.666\n",
            "step 59500, train accuracy 0.72 , loss 276.088\n",
            "step 59600, train accuracy 0.69 , loss 1224.06\n",
            "step 59700, train accuracy 0.7 , loss 306.164\n",
            "step 59800, train accuracy 0.68 , loss 212.375\n",
            "step 59900, train accuracy 0.61 , loss 872.755\n",
            "step 60000, train accuracy 0.7 , loss 341.652\n",
            "step 60100, train accuracy 0.75 , loss 277.027\n",
            "step 60200, train accuracy 0.71 , loss 837.815\n",
            "step 60300, train accuracy 0.81 , loss 212.145\n",
            "step 60400, train accuracy 0.6 , loss 139.528\n",
            "step 60500, train accuracy 0.68 , loss 1030.26\n",
            "step 60600, train accuracy 0.75 , loss 844.509\n",
            "step 60700, train accuracy 0.68 , loss 173.739\n",
            "step 60800, train accuracy 0.74 , loss 911.493\n",
            "step 60900, train accuracy 0.62 , loss 177.778\n",
            "step 61000, train accuracy 0.56 , loss 204.912\n",
            "step 61100, train accuracy 0.7 , loss 1235.18\n",
            "step 61200, train accuracy 0.7 , loss 946.307\n",
            "step 61300, train accuracy 0.71 , loss 1089.81\n",
            "step 61400, train accuracy 0.75 , loss 1015.4\n",
            "step 61500, train accuracy 0.78 , loss 1009.39\n",
            "step 61600, train accuracy 0.73 , loss 934.244\n",
            "step 61700, train accuracy 0.61 , loss 920.451\n",
            "step 61800, train accuracy 0.84 , loss 228.296\n",
            "step 61900, train accuracy 0.71 , loss 450.747\n",
            "step 62000, train accuracy 0.76 , loss 916.341\n",
            "step 62100, train accuracy 0.78 , loss 194.684\n",
            "step 62200, train accuracy 0.75 , loss 431.131\n",
            "step 62300, train accuracy 0.63 , loss 239.163\n",
            "step 62400, train accuracy 0.75 , loss 716.739\n",
            "step 62500, train accuracy 0.66 , loss 1089.05\n",
            "step 62600, train accuracy 0.73 , loss 980.269\n",
            "step 62700, train accuracy 0.66 , loss 353.979\n",
            "step 62800, train accuracy 0.67 , loss 202.515\n",
            "step 62900, train accuracy 0.79 , loss 663.707\n",
            "step 63000, train accuracy 0.7 , loss 1199.9\n",
            "step 63100, train accuracy 0.73 , loss 1164.75\n",
            "step 63200, train accuracy 0.75 , loss 991.154\n",
            "step 63300, train accuracy 0.66 , loss 374.632\n",
            "step 63400, train accuracy 0.63 , loss 291.315\n",
            "step 63500, train accuracy 0.63 , loss 1171.21\n",
            "step 63600, train accuracy 0.75 , loss 1107.18\n",
            "step 63700, train accuracy 0.75 , loss 1066.42\n",
            "step 63800, train accuracy 0.6 , loss 1370.64\n",
            "step 63900, train accuracy 0.7 , loss 1098.69\n",
            "step 64000, train accuracy 0.78 , loss 163.385\n",
            "step 64100, train accuracy 0.76 , loss 885.597\n",
            "step 64200, train accuracy 0.8 , loss 1033.1\n",
            "step 64300, train accuracy 0.69 , loss 541.66\n",
            "step 64400, train accuracy 0.77 , loss 718.009\n",
            "step 64500, train accuracy 0.63 , loss 997.688\n",
            "step 64600, train accuracy 0.7 , loss 298.284\n",
            "step 64700, train accuracy 0.67 , loss 319.807\n",
            "step 64800, train accuracy 0.74 , loss 287.481\n",
            "step 64900, train accuracy 0.81 , loss 268.486\n",
            "step 65000, train accuracy 0.69 , loss 676.291\n",
            "step 65100, train accuracy 0.72 , loss 214.45\n",
            "step 65200, train accuracy 0.64 , loss 264.84\n",
            "step 65300, train accuracy 0.67 , loss 433.632\n",
            "step 65400, train accuracy 0.8 , loss 266.735\n",
            "step 65500, train accuracy 0.81 , loss 238.387\n",
            "step 65600, train accuracy 0.65 , loss 422.599\n",
            "step 65700, train accuracy 0.6 , loss 265.172\n",
            "step 65800, train accuracy 0.88 , loss 768.652\n",
            "step 65900, train accuracy 0.64 , loss 903.607\n",
            "step 66000, train accuracy 0.69 , loss 454.114\n",
            "step 66100, train accuracy 0.7 , loss 1122.45\n",
            "step 66200, train accuracy 0.74 , loss 870.395\n",
            "step 66300, train accuracy 0.61 , loss 1042.67\n",
            "step 66400, train accuracy 0.74 , loss 585.789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 66500, train accuracy 0.67 , loss 287.985\n",
            "step 66600, train accuracy 0.71 , loss 1041.49\n",
            "step 66700, train accuracy 0.66 , loss 1007.91\n",
            "step 66800, train accuracy 0.73 , loss 960.357\n",
            "step 66900, train accuracy 0.59 , loss 253.261\n",
            "step 67000, train accuracy 0.82 , loss 958.011\n",
            "step 67100, train accuracy 0.75 , loss 429.538\n",
            "step 67200, train accuracy 0.72 , loss 982.948\n",
            "step 67300, train accuracy 0.73 , loss 686.727\n",
            "step 67400, train accuracy 0.66 , loss 783.994\n",
            "step 67500, train accuracy 0.68 , loss 167.037\n",
            "step 67600, train accuracy 0.79 , loss 278.639\n",
            "step 67700, train accuracy 0.72 , loss 372.777\n",
            "step 67800, train accuracy 0.7 , loss 733.479\n",
            "step 67900, train accuracy 0.64 , loss 251.496\n",
            "step 68000, train accuracy 0.73 , loss 803.855\n",
            "step 68100, train accuracy 0.71 , loss 935.705\n",
            "step 68200, train accuracy 0.75 , loss 1002.99\n",
            "step 68300, train accuracy 0.75 , loss 216.836\n",
            "step 68400, train accuracy 0.65 , loss 184.299\n",
            "step 68500, train accuracy 0.65 , loss 1385.44\n",
            "step 68600, train accuracy 0.64 , loss 842.8\n",
            "step 68700, train accuracy 0.72 , loss 1067.97\n",
            "step 68800, train accuracy 0.64 , loss 786.141\n",
            "step 68900, train accuracy 0.76 , loss 235.676\n",
            "step 69000, train accuracy 0.72 , loss 224.33\n",
            "step 69100, train accuracy 0.59 , loss 905.013\n",
            "step 69200, train accuracy 0.76 , loss 294.81\n",
            "step 69300, train accuracy 0.74 , loss 855.471\n",
            "step 69400, train accuracy 0.64 , loss 652.754\n",
            "step 69500, train accuracy 0.68 , loss 338.848\n",
            "step 69600, train accuracy 0.73 , loss 351.777\n",
            "step 69700, train accuracy 0.78 , loss 852.484\n",
            "step 69800, train accuracy 0.66 , loss 364.06\n",
            "step 69900, train accuracy 0.71 , loss 404.981\n",
            "step 70000, train accuracy 0.59 , loss 985.29\n",
            "step 70100, train accuracy 0.7 , loss 1067.76\n",
            "step 70200, train accuracy 0.68 , loss 1106.05\n",
            "step 70300, train accuracy 0.72 , loss 865.859\n",
            "step 70400, train accuracy 0.61 , loss 204.35\n",
            "step 70500, train accuracy 0.66 , loss 284.958\n",
            "step 70600, train accuracy 0.68 , loss 1015.46\n",
            "step 70700, train accuracy 0.65 , loss 261.797\n",
            "step 70800, train accuracy 0.67 , loss 1067.57\n",
            "step 70900, train accuracy 0.68 , loss 995.798\n",
            "step 71000, train accuracy 0.72 , loss 207.951\n",
            "step 71100, train accuracy 0.75 , loss 255.595\n",
            "step 71200, train accuracy 0.65 , loss 804.509\n",
            "step 71300, train accuracy 0.62 , loss 817.952\n",
            "step 71400, train accuracy 0.8 , loss 339.521\n",
            "step 71500, train accuracy 0.64 , loss 268.745\n",
            "step 71600, train accuracy 0.83 , loss 846.329\n",
            "step 71700, train accuracy 0.74 , loss 316.079\n",
            "step 71800, train accuracy 0.75 , loss 437.007\n",
            "step 71900, train accuracy 0.7 , loss 995.161\n",
            "step 72000, train accuracy 0.68 , loss 126.532\n",
            "step 72100, train accuracy 0.71 , loss 155.103\n",
            "step 72200, train accuracy 0.76 , loss 233.614\n",
            "step 72300, train accuracy 0.74 , loss 265.916\n",
            "step 72400, train accuracy 0.65 , loss 360.885\n",
            "step 72500, train accuracy 0.69 , loss 765.105\n",
            "step 72600, train accuracy 0.78 , loss 874.02\n",
            "step 72700, train accuracy 0.59 , loss 912.246\n",
            "step 72800, train accuracy 0.62 , loss 719.969\n",
            "step 72900, train accuracy 0.76 , loss 846.7\n",
            "step 73000, train accuracy 0.64 , loss 213.366\n",
            "step 73100, train accuracy 0.63 , loss 364.94\n",
            "step 73200, train accuracy 0.77 , loss 857.645\n",
            "step 73300, train accuracy 0.76 , loss 126.732\n",
            "step 73400, train accuracy 0.61 , loss 265.245\n",
            "step 73500, train accuracy 0.69 , loss 740.296\n",
            "step 73600, train accuracy 0.76 , loss 108.65\n",
            "step 73700, train accuracy 0.71 , loss 762.081\n",
            "step 73800, train accuracy 0.78 , loss 745.528\n",
            "step 73900, train accuracy 0.68 , loss 789.153\n",
            "step 74000, train accuracy 0.68 , loss 234.357\n",
            "step 74100, train accuracy 0.65 , loss 713.472\n",
            "step 74200, train accuracy 0.64 , loss 820.933\n",
            "step 74300, train accuracy 0.73 , loss 346.238\n",
            "step 74400, train accuracy 0.65 , loss 642.096\n",
            "step 74500, train accuracy 0.6 , loss 697.256\n",
            "step 74600, train accuracy 0.71 , loss 889.075\n",
            "step 74700, train accuracy 0.75 , loss 780.575\n",
            "step 74800, train accuracy 0.78 , loss 357.267\n",
            "step 74900, train accuracy 0.61 , loss 982.138\n",
            "step 75000, train accuracy 0.76 , loss 260.407\n",
            "step 75100, train accuracy 0.67 , loss 608.608\n",
            "step 75200, train accuracy 0.67 , loss 240.701\n",
            "step 75300, train accuracy 0.76 , loss 809.76\n",
            "step 75400, train accuracy 0.66 , loss 204.854\n",
            "step 75500, train accuracy 0.71 , loss 990.734\n",
            "step 75600, train accuracy 0.7 , loss 251.075\n",
            "step 75700, train accuracy 0.72 , loss 786.794\n",
            "step 75800, train accuracy 0.65 , loss 791.037\n",
            "step 75900, train accuracy 0.65 , loss 466.665\n",
            "step 76000, train accuracy 0.72 , loss 759.186\n",
            "step 76100, train accuracy 0.67 , loss 174.551\n",
            "step 76200, train accuracy 0.73 , loss 906.077\n",
            "step 76300, train accuracy 0.69 , loss 718.577\n",
            "step 76400, train accuracy 0.6 , loss 985.592\n",
            "step 76500, train accuracy 0.69 , loss 721.331\n",
            "step 76600, train accuracy 0.66 , loss 289.742\n",
            "step 76700, train accuracy 0.7 , loss 565.964\n",
            "step 76800, train accuracy 0.73 , loss 310.945\n",
            "step 76900, train accuracy 0.74 , loss 678.828\n",
            "step 77000, train accuracy 0.69 , loss 108.826\n",
            "step 77100, train accuracy 0.62 , loss 712.623\n",
            "step 77200, train accuracy 0.67 , loss 283.775\n",
            "step 77300, train accuracy 0.65 , loss 505.183\n",
            "step 77400, train accuracy 0.79 , loss 135.451\n",
            "step 77500, train accuracy 0.71 , loss 819.745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 77600, train accuracy 0.69 , loss 222.86\n",
            "step 77700, train accuracy 0.79 , loss 207.011\n",
            "step 77800, train accuracy 0.76 , loss 807.267\n",
            "step 77900, train accuracy 0.58 , loss 237.66\n",
            "step 78000, train accuracy 0.74 , loss 884.496\n",
            "step 78100, train accuracy 0.68 , loss 835.51\n",
            "step 78200, train accuracy 0.83 , loss 887.93\n",
            "step 78300, train accuracy 0.79 , loss 308.637\n",
            "step 78400, train accuracy 0.63 , loss 858.236\n",
            "step 78500, train accuracy 0.59 , loss 319.202\n",
            "step 78600, train accuracy 0.76 , loss 201.524\n",
            "step 78700, train accuracy 0.68 , loss 614.641\n",
            "step 78800, train accuracy 0.7 , loss 732.266\n",
            "step 78900, train accuracy 0.68 , loss 772.333\n",
            "step 79000, train accuracy 0.69 , loss 326.089\n",
            "step 79100, train accuracy 0.64 , loss 810.616\n",
            "step 79200, train accuracy 0.58 , loss 319.924\n",
            "step 79300, train accuracy 0.67 , loss 935.006\n",
            "step 79400, train accuracy 0.58 , loss 328.116\n",
            "step 79500, train accuracy 0.61 , loss 280.583\n",
            "step 79600, train accuracy 0.71 , loss 267.311\n",
            "step 79700, train accuracy 0.66 , loss 629.332\n",
            "step 79800, train accuracy 0.75 , loss 314.677\n",
            "step 79900, train accuracy 0.73 , loss 517.285\n",
            "step 80000, train accuracy 0.69 , loss 782.296\n",
            "step 80100, train accuracy 0.64 , loss 560.26\n",
            "step 80200, train accuracy 0.71 , loss 739.818\n",
            "step 80300, train accuracy 0.76 , loss 304.793\n",
            "step 80400, train accuracy 0.7 , loss 947.684\n",
            "step 80500, train accuracy 0.69 , loss 430.044\n",
            "step 80600, train accuracy 0.71 , loss 198.334\n",
            "step 80700, train accuracy 0.8 , loss 252.458\n",
            "step 80800, train accuracy 0.6 , loss 293.233\n",
            "step 80900, train accuracy 0.75 , loss 141.935\n",
            "step 81000, train accuracy 0.83 , loss 209.684\n",
            "step 81100, train accuracy 0.75 , loss 661.825\n",
            "step 81200, train accuracy 0.81 , loss 163.785\n",
            "step 81300, train accuracy 0.82 , loss 903.16\n",
            "step 81400, train accuracy 0.78 , loss 267.604\n",
            "step 81500, train accuracy 0.71 , loss 868.301\n",
            "step 81600, train accuracy 0.8 , loss 170.192\n",
            "step 81700, train accuracy 0.77 , loss 316.598\n",
            "step 81800, train accuracy 0.69 , loss 999.253\n",
            "step 81900, train accuracy 0.67 , loss 308.811\n",
            "step 82000, train accuracy 0.73 , loss 386.935\n",
            "step 82100, train accuracy 0.73 , loss 797.602\n",
            "step 82200, train accuracy 0.73 , loss 783.347\n",
            "step 82300, train accuracy 0.7 , loss 796.298\n",
            "step 82400, train accuracy 0.76 , loss 1072.35\n",
            "step 82500, train accuracy 0.72 , loss 790.774\n",
            "step 82600, train accuracy 0.55 , loss 360.351\n",
            "step 82700, train accuracy 0.73 , loss 155.102\n",
            "step 82800, train accuracy 0.69 , loss 822.343\n",
            "step 82900, train accuracy 0.84 , loss 284.373\n",
            "step 83000, train accuracy 0.7 , loss 799.957\n",
            "step 83100, train accuracy 0.73 , loss 308.582\n",
            "step 83200, train accuracy 0.74 , loss 132.595\n",
            "step 83300, train accuracy 0.69 , loss 891.096\n",
            "step 83400, train accuracy 0.76 , loss 942.69\n",
            "step 83500, train accuracy 0.78 , loss 356.791\n",
            "step 83600, train accuracy 0.79 , loss 309.942\n",
            "step 83700, train accuracy 0.81 , loss 158.71\n",
            "step 83800, train accuracy 0.61 , loss 459.397\n",
            "step 83900, train accuracy 0.67 , loss 172.614\n",
            "step 84000, train accuracy 0.8 , loss 842.013\n",
            "step 84100, train accuracy 0.79 , loss 308.323\n",
            "step 84200, train accuracy 0.76 , loss 259.785\n",
            "step 84300, train accuracy 0.77 , loss 854.954\n",
            "step 84400, train accuracy 0.74 , loss 718.908\n",
            "step 84500, train accuracy 0.78 , loss 795.568\n",
            "step 84600, train accuracy 0.84 , loss 183.927\n",
            "step 84700, train accuracy 0.85 , loss 195.928\n",
            "step 84800, train accuracy 0.74 , loss 802.529\n",
            "step 84900, train accuracy 0.7 , loss 230.905\n",
            "step 85000, train accuracy 0.66 , loss 823.21\n",
            "step 85100, train accuracy 0.8 , loss 822.948\n",
            "step 85200, train accuracy 0.73 , loss 316.235\n",
            "step 85300, train accuracy 0.7 , loss 197.294\n",
            "step 85400, train accuracy 0.74 , loss 624.373\n",
            "step 85500, train accuracy 0.65 , loss 597.318\n",
            "step 85600, train accuracy 0.67 , loss 785.693\n",
            "step 85700, train accuracy 0.71 , loss 446.697\n",
            "step 85800, train accuracy 0.66 , loss 1098.16\n",
            "step 85900, train accuracy 0.66 , loss 195.211\n",
            "step 86000, train accuracy 0.74 , loss 981.437\n",
            "step 86100, train accuracy 0.72 , loss 247.186\n",
            "step 86200, train accuracy 0.75 , loss 973.816\n",
            "step 86300, train accuracy 0.73 , loss 366.889\n",
            "step 86400, train accuracy 0.72 , loss 880.763\n",
            "step 86500, train accuracy 0.72 , loss 921.54\n",
            "step 86600, train accuracy 0.77 , loss 656.586\n",
            "step 86700, train accuracy 0.73 , loss 499.114\n",
            "step 86800, train accuracy 0.67 , loss 521.008\n",
            "step 86900, train accuracy 0.62 , loss 825.077\n",
            "step 87000, train accuracy 0.67 , loss 677.353\n",
            "step 87100, train accuracy 0.7 , loss 731.664\n",
            "step 87200, train accuracy 0.7 , loss 686.229\n",
            "step 87300, train accuracy 0.68 , loss 331.614\n",
            "step 87400, train accuracy 0.71 , loss 607.443\n",
            "step 87500, train accuracy 0.7 , loss 695.075\n",
            "step 87600, train accuracy 0.64 , loss 259.58\n",
            "step 87700, train accuracy 0.59 , loss 624.639\n",
            "step 87800, train accuracy 0.69 , loss 311.143\n",
            "step 87900, train accuracy 0.72 , loss 790.987\n",
            "step 88000, train accuracy 0.75 , loss 159.192\n",
            "step 88100, train accuracy 0.7 , loss 716.396\n",
            "step 88200, train accuracy 0.64 , loss 630.76\n",
            "step 88300, train accuracy 0.73 , loss 284.524\n",
            "step 88400, train accuracy 0.61 , loss 693.282\n",
            "step 88500, train accuracy 0.66 , loss 391.734\n",
            "step 88600, train accuracy 0.67 , loss 287.215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 88700, train accuracy 0.66 , loss 290.515\n",
            "step 88800, train accuracy 0.77 , loss 130.311\n",
            "step 88900, train accuracy 0.75 , loss 324.272\n",
            "step 89000, train accuracy 0.63 , loss 713.73\n",
            "step 89100, train accuracy 0.71 , loss 687.081\n",
            "step 89200, train accuracy 0.67 , loss 341.322\n",
            "step 89300, train accuracy 0.59 , loss 734.963\n",
            "step 89400, train accuracy 0.61 , loss 541.01\n",
            "step 89500, train accuracy 0.72 , loss 319.352\n",
            "step 89600, train accuracy 0.68 , loss 308.851\n",
            "step 89700, train accuracy 0.69 , loss 798.899\n",
            "step 89800, train accuracy 0.68 , loss 217.618\n",
            "step 89900, train accuracy 0.59 , loss 291.337\n",
            "step 90000, train accuracy 0.69 , loss 213.225\n",
            "step 90100, train accuracy 0.78 , loss 802.841\n",
            "step 90200, train accuracy 0.76 , loss 199.236\n",
            "step 90300, train accuracy 0.73 , loss 707.866\n",
            "step 90400, train accuracy 0.69 , loss 797.461\n",
            "step 90500, train accuracy 0.59 , loss 230.511\n",
            "step 90600, train accuracy 0.75 , loss 172.473\n",
            "step 90700, train accuracy 0.62 , loss 174.997\n",
            "step 90800, train accuracy 0.7 , loss 737.907\n",
            "step 90900, train accuracy 0.64 , loss 625.768\n",
            "step 91000, train accuracy 0.65 , loss 717.151\n",
            "step 91100, train accuracy 0.86 , loss 219.199\n",
            "step 91200, train accuracy 0.67 , loss 628.392\n",
            "step 91300, train accuracy 0.67 , loss 435.922\n",
            "step 91400, train accuracy 0.56 , loss 786.972\n",
            "step 91500, train accuracy 0.73 , loss 206.746\n",
            "step 91600, train accuracy 0.79 , loss 246.411\n",
            "step 91700, train accuracy 0.7 , loss 269.106\n",
            "step 91800, train accuracy 0.63 , loss 201.253\n",
            "step 91900, train accuracy 0.8 , loss 259.742\n",
            "step 92000, train accuracy 0.62 , loss 299.997\n",
            "step 92100, train accuracy 0.76 , loss 579.128\n",
            "step 92200, train accuracy 0.87 , loss 566.418\n",
            "step 92300, train accuracy 0.66 , loss 1057.42\n",
            "step 92400, train accuracy 0.71 , loss 679.874\n",
            "step 92500, train accuracy 0.72 , loss 433.79\n",
            "step 92600, train accuracy 0.58 , loss 232.399\n",
            "step 92700, train accuracy 0.7 , loss 249.384\n",
            "step 92800, train accuracy 0.65 , loss 236.286\n",
            "step 92900, train accuracy 0.75 , loss 888.238\n",
            "step 93000, train accuracy 0.62 , loss 799.477\n",
            "step 93100, train accuracy 0.74 , loss 833.796\n",
            "step 93200, train accuracy 0.79 , loss 128.257\n",
            "step 93300, train accuracy 0.8 , loss 225.253\n",
            "step 93400, train accuracy 0.65 , loss 803.779\n",
            "step 93500, train accuracy 0.77 , loss 246.633\n",
            "step 93600, train accuracy 0.65 , loss 198.384\n",
            "step 93700, train accuracy 0.72 , loss 771.883\n",
            "step 93800, train accuracy 0.71 , loss 657.57\n",
            "step 93900, train accuracy 0.65 , loss 328.544\n",
            "step 94000, train accuracy 0.74 , loss 627.907\n",
            "step 94100, train accuracy 0.76 , loss 671.739\n",
            "step 94200, train accuracy 0.78 , loss 776.596\n",
            "step 94300, train accuracy 0.73 , loss 330.944\n",
            "step 94400, train accuracy 0.75 , loss 169.453\n",
            "step 94500, train accuracy 0.8 , loss 884.816\n",
            "step 94600, train accuracy 0.76 , loss 858.403\n",
            "step 94700, train accuracy 0.77 , loss 748.371\n",
            "step 94800, train accuracy 0.72 , loss 201.977\n",
            "step 94900, train accuracy 0.69 , loss 208.514\n",
            "step 95000, train accuracy 0.66 , loss 327.212\n",
            "step 95100, train accuracy 0.61 , loss 453.989\n",
            "step 95200, train accuracy 0.66 , loss 704.767\n",
            "step 95300, train accuracy 0.71 , loss 282.439\n",
            "step 95400, train accuracy 0.66 , loss 615.131\n",
            "step 95500, train accuracy 0.75 , loss 373.089\n",
            "step 95600, train accuracy 0.76 , loss 193.303\n",
            "step 95700, train accuracy 0.65 , loss 701.744\n",
            "step 95800, train accuracy 0.62 , loss 794.339\n",
            "step 95900, train accuracy 0.76 , loss 774.215\n",
            "step 96000, train accuracy 0.78 , loss 213.096\n",
            "step 96100, train accuracy 0.78 , loss 641.086\n",
            "step 96200, train accuracy 0.72 , loss 685.536\n",
            "step 96300, train accuracy 0.86 , loss 793.665\n",
            "step 96400, train accuracy 0.72 , loss 592.359\n",
            "step 96500, train accuracy 0.65 , loss 693.334\n",
            "step 96600, train accuracy 0.69 , loss 250.718\n",
            "step 96700, train accuracy 0.78 , loss 296.708\n",
            "step 96800, train accuracy 0.69 , loss 537.819\n",
            "step 96900, train accuracy 0.78 , loss 669.778\n",
            "step 97000, train accuracy 0.8 , loss 253.625\n",
            "step 97100, train accuracy 0.69 , loss 281.807\n",
            "step 97200, train accuracy 0.66 , loss 651.822\n",
            "step 97300, train accuracy 0.66 , loss 151.009\n",
            "step 97400, train accuracy 0.8 , loss 943.766\n",
            "step 97500, train accuracy 0.68 , loss 350.848\n",
            "step 97600, train accuracy 0.72 , loss 542.445\n",
            "step 97700, train accuracy 0.64 , loss 796.379\n",
            "step 97800, train accuracy 0.69 , loss 734.139\n",
            "step 97900, train accuracy 0.83 , loss 374.313\n",
            "step 98000, train accuracy 0.67 , loss 658.968\n",
            "step 98100, train accuracy 0.69 , loss 608.333\n",
            "step 98200, train accuracy 0.58 , loss 823.112\n",
            "step 98300, train accuracy 0.65 , loss 258.889\n",
            "step 98400, train accuracy 0.77 , loss 769.268\n",
            "step 98500, train accuracy 0.75 , loss 339.201\n",
            "step 98600, train accuracy 0.6 , loss 664.778\n",
            "step 98700, train accuracy 0.66 , loss 283.505\n",
            "step 98800, train accuracy 0.65 , loss 278.025\n",
            "step 98900, train accuracy 0.65 , loss 332.939\n",
            "step 99000, train accuracy 0.77 , loss 644.726\n",
            "step 99100, train accuracy 0.67 , loss 612.337\n",
            "step 99200, train accuracy 0.7 , loss 632.443\n",
            "step 99300, train accuracy 0.7 , loss 695.249\n",
            "step 99400, train accuracy 0.7 , loss 633.432\n",
            "step 99500, train accuracy 0.63 , loss 509.706\n",
            "step 99600, train accuracy 0.73 , loss 722.493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 99700, train accuracy 0.63 , loss 247.233\n",
            "step 99800, train accuracy 0.8 , loss 671.053\n",
            "step 99900, train accuracy 0.61 , loss 531.579\n",
            "step 100000, train accuracy 0.69 , loss 445.105\n",
            "step 100100, train accuracy 0.62 , loss 710.263\n",
            "step 100200, train accuracy 0.7 , loss 379.345\n",
            "step 100300, train accuracy 0.7 , loss 649.177\n",
            "step 100400, train accuracy 0.61 , loss 608.506\n",
            "step 100500, train accuracy 0.69 , loss 354.781\n",
            "step 100600, train accuracy 0.72 , loss 628.391\n",
            "step 100700, train accuracy 0.77 , loss 295.077\n",
            "step 100800, train accuracy 0.63 , loss 629.229\n",
            "step 100900, train accuracy 0.56 , loss 296.828\n",
            "step 101000, train accuracy 0.68 , loss 352.898\n",
            "step 101100, train accuracy 0.78 , loss 339.875\n",
            "step 101200, train accuracy 0.73 , loss 566.932\n",
            "step 101300, train accuracy 0.69 , loss 192.011\n",
            "step 101400, train accuracy 0.64 , loss 577.208\n",
            "step 101500, train accuracy 0.76 , loss 726.955\n",
            "step 101600, train accuracy 0.66 , loss 530.462\n",
            "step 101700, train accuracy 0.7 , loss 693.453\n",
            "step 101800, train accuracy 0.66 , loss 696.195\n",
            "step 101900, train accuracy 0.66 , loss 309.563\n",
            "step 102000, train accuracy 0.73 , loss 412.661\n",
            "step 102100, train accuracy 0.58 , loss 355.069\n",
            "step 102200, train accuracy 0.72 , loss 219.825\n",
            "step 102300, train accuracy 0.65 , loss 593.636\n",
            "step 102400, train accuracy 0.59 , loss 318.342\n",
            "step 102500, train accuracy 0.71 , loss 449.887\n",
            "step 102600, train accuracy 0.61 , loss 544.458\n",
            "step 102700, train accuracy 0.72 , loss 266.026\n",
            "step 102800, train accuracy 0.63 , loss 323.595\n",
            "step 102900, train accuracy 0.6 , loss 339.003\n",
            "step 103000, train accuracy 0.6 , loss 679.761\n",
            "step 103100, train accuracy 0.75 , loss 625.959\n",
            "step 103200, train accuracy 0.65 , loss 620.063\n",
            "step 103300, train accuracy 0.63 , loss 281.29\n",
            "step 103400, train accuracy 0.73 , loss 309.732\n",
            "step 103500, train accuracy 0.62 , loss 783.877\n",
            "step 103600, train accuracy 0.69 , loss 279.635\n",
            "step 103700, train accuracy 0.73 , loss 666.157\n",
            "step 103800, train accuracy 0.68 , loss 711.96\n",
            "step 103900, train accuracy 0.57 , loss 413.901\n",
            "step 104000, train accuracy 0.51 , loss 704.913\n",
            "step 104100, train accuracy 0.76 , loss 811.67\n",
            "step 104200, train accuracy 0.68 , loss 683.044\n",
            "step 104300, train accuracy 0.65 , loss 503.039\n",
            "step 104400, train accuracy 0.64 , loss 187.91\n",
            "step 104500, train accuracy 0.66 , loss 615.725\n",
            "step 104600, train accuracy 0.67 , loss 330.082\n",
            "step 104700, train accuracy 0.61 , loss 575.536\n",
            "step 104800, train accuracy 0.7 , loss 511.538\n",
            "step 104900, train accuracy 0.56 , loss 655.076\n",
            "step 105000, train accuracy 0.62 , loss 663.018\n",
            "step 105100, train accuracy 0.55 , loss 623.24\n",
            "step 105200, train accuracy 0.68 , loss 403.254\n",
            "step 105300, train accuracy 0.71 , loss 415.355\n",
            "step 105400, train accuracy 0.68 , loss 398.785\n",
            "step 105500, train accuracy 0.64 , loss 671.36\n",
            "step 105600, train accuracy 0.72 , loss 333.539\n",
            "step 105700, train accuracy 0.68 , loss 462.086\n",
            "step 105800, train accuracy 0.69 , loss 372.95\n",
            "step 105900, train accuracy 0.65 , loss 510.688\n",
            "step 106000, train accuracy 0.71 , loss 698.087\n",
            "step 106100, train accuracy 0.66 , loss 538.717\n",
            "step 106200, train accuracy 0.68 , loss 483.469\n",
            "step 106300, train accuracy 0.72 , loss 154.639\n",
            "step 106400, train accuracy 0.6 , loss 601.516\n",
            "step 106500, train accuracy 0.64 , loss 556.343\n",
            "step 106600, train accuracy 0.72 , loss 375.626\n",
            "step 106700, train accuracy 0.75 , loss 219.323\n",
            "step 106800, train accuracy 0.81 , loss 329.898\n",
            "step 106900, train accuracy 0.84 , loss 283.284\n",
            "step 107000, train accuracy 0.72 , loss 201.213\n",
            "step 107100, train accuracy 0.69 , loss 475.414\n",
            "step 107200, train accuracy 0.68 , loss 221.11\n",
            "step 107300, train accuracy 0.71 , loss 377.664\n",
            "step 107400, train accuracy 0.76 , loss 594.354\n",
            "step 107500, train accuracy 0.79 , loss 751.07\n",
            "step 107600, train accuracy 0.8 , loss 295.863\n",
            "step 107700, train accuracy 0.62 , loss 577.638\n",
            "step 107800, train accuracy 0.55 , loss 667.057\n",
            "step 107900, train accuracy 0.61 , loss 340.144\n",
            "step 108000, train accuracy 0.63 , loss 268.577\n",
            "step 108100, train accuracy 0.63 , loss 544.942\n",
            "step 108200, train accuracy 0.6 , loss 764.935\n",
            "step 108300, train accuracy 0.66 , loss 253.528\n",
            "step 108400, train accuracy 0.57 , loss 145.747\n",
            "step 108500, train accuracy 0.67 , loss 402.071\n",
            "step 108600, train accuracy 0.67 , loss 206.859\n",
            "step 108700, train accuracy 0.62 , loss 233.215\n",
            "step 108800, train accuracy 0.72 , loss 576.171\n",
            "step 108900, train accuracy 0.78 , loss 418.406\n",
            "step 109000, train accuracy 0.67 , loss 656.062\n",
            "step 109100, train accuracy 0.7 , loss 570.031\n",
            "step 109200, train accuracy 0.68 , loss 182.439\n",
            "step 109300, train accuracy 0.67 , loss 584.022\n",
            "step 109400, train accuracy 0.82 , loss 220.969\n",
            "step 109500, train accuracy 0.73 , loss 336.466\n",
            "step 109600, train accuracy 0.64 , loss 676.628\n",
            "step 109700, train accuracy 0.78 , loss 197.282\n",
            "step 109800, train accuracy 0.7 , loss 761.534\n",
            "step 109900, train accuracy 0.73 , loss 281.234\n",
            "step 110000, train accuracy 0.79 , loss 611.678\n",
            "step 110100, train accuracy 0.69 , loss 242.302\n",
            "step 110200, train accuracy 0.68 , loss 106.724\n",
            "step 110300, train accuracy 0.66 , loss 240.615\n",
            "step 110400, train accuracy 0.82 , loss 207.517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 110500, train accuracy 0.73 , loss 526.079\n",
            "step 110600, train accuracy 0.69 , loss 486.523\n",
            "step 110700, train accuracy 0.71 , loss 619.881\n",
            "step 110800, train accuracy 0.77 , loss 312.271\n",
            "step 110900, train accuracy 0.67 , loss 581.522\n",
            "step 111000, train accuracy 0.69 , loss 248.822\n",
            "step 111100, train accuracy 0.74 , loss 662.753\n",
            "step 111200, train accuracy 0.74 , loss 244.469\n",
            "step 111300, train accuracy 0.69 , loss 691.844\n",
            "step 111400, train accuracy 0.65 , loss 277.298\n",
            "step 111500, train accuracy 0.73 , loss 212.965\n",
            "step 111600, train accuracy 0.75 , loss 341.653\n",
            "step 111700, train accuracy 0.76 , loss 255.643\n",
            "step 111800, train accuracy 0.69 , loss 598.281\n",
            "step 111900, train accuracy 0.68 , loss 270.219\n",
            "step 112000, train accuracy 0.77 , loss 600.157\n",
            "step 112100, train accuracy 0.77 , loss 303.116\n",
            "step 112200, train accuracy 0.71 , loss 591.601\n",
            "step 112300, train accuracy 0.75 , loss 295.647\n",
            "step 112400, train accuracy 0.76 , loss 814.475\n",
            "step 112500, train accuracy 0.72 , loss 671.581\n",
            "step 112600, train accuracy 0.72 , loss 312.407\n",
            "step 112700, train accuracy 0.75 , loss 280.853\n",
            "step 112800, train accuracy 0.78 , loss 193.263\n",
            "step 112900, train accuracy 0.78 , loss 149.264\n",
            "step 113000, train accuracy 0.82 , loss 173.409\n",
            "step 113100, train accuracy 0.84 , loss 593.096\n",
            "step 113200, train accuracy 0.76 , loss 600.701\n",
            "step 113300, train accuracy 0.79 , loss 145.937\n",
            "step 113400, train accuracy 0.78 , loss 628.195\n",
            "step 113500, train accuracy 0.81 , loss 666.22\n",
            "step 113600, train accuracy 0.69 , loss 578.228\n",
            "step 113700, train accuracy 0.73 , loss 556.531\n",
            "step 113800, train accuracy 0.6 , loss 519.793\n",
            "step 113900, train accuracy 0.75 , loss 213.213\n",
            "step 114000, train accuracy 0.78 , loss 570.966\n",
            "step 114100, train accuracy 0.71 , loss 240.724\n",
            "step 114200, train accuracy 0.79 , loss 519.494\n",
            "step 114300, train accuracy 0.73 , loss 258.896\n",
            "step 114400, train accuracy 0.9 , loss 186.001\n",
            "step 114500, train accuracy 0.69 , loss 637.489\n",
            "step 114600, train accuracy 0.83 , loss 585.767\n",
            "step 114700, train accuracy 0.74 , loss 255.242\n",
            "step 114800, train accuracy 0.72 , loss 721.115\n",
            "step 114900, train accuracy 0.69 , loss 175.763\n",
            "step 115000, train accuracy 0.76 , loss 657.516\n",
            "step 115100, train accuracy 0.72 , loss 227.429\n",
            "step 115200, train accuracy 0.7 , loss 478.424\n",
            "step 115300, train accuracy 0.76 , loss 844.656\n",
            "step 115400, train accuracy 0.75 , loss 244.661\n",
            "step 115500, train accuracy 0.65 , loss 232.877\n",
            "step 115600, train accuracy 0.78 , loss 186.836\n",
            "step 115700, train accuracy 0.79 , loss 215.38\n",
            "step 115800, train accuracy 0.71 , loss 472.982\n",
            "step 115900, train accuracy 0.69 , loss 220.474\n",
            "step 116000, train accuracy 0.67 , loss 499.307\n",
            "step 116100, train accuracy 0.83 , loss 263.045\n",
            "step 116200, train accuracy 0.72 , loss 156.21\n",
            "step 116300, train accuracy 0.7 , loss 255.109\n",
            "step 116400, train accuracy 0.77 , loss 696.464\n",
            "step 116500, train accuracy 0.85 , loss 180.539\n",
            "step 116600, train accuracy 0.85 , loss 213.132\n",
            "step 116700, train accuracy 0.69 , loss 168.206\n",
            "step 116800, train accuracy 0.68 , loss 532.833\n",
            "step 116900, train accuracy 0.75 , loss 467.406\n",
            "step 117000, train accuracy 0.77 , loss 216.039\n",
            "step 117100, train accuracy 0.75 , loss 114.871\n",
            "step 117200, train accuracy 0.72 , loss 230.091\n",
            "step 117300, train accuracy 0.78 , loss 810.821\n",
            "step 117400, train accuracy 0.74 , loss 282.154\n",
            "step 117500, train accuracy 0.7 , loss 181.698\n",
            "step 117600, train accuracy 0.82 , loss 220.835\n",
            "step 117700, train accuracy 0.71 , loss 728.846\n",
            "step 117800, train accuracy 0.72 , loss 752.09\n",
            "step 117900, train accuracy 0.77 , loss 541.39\n",
            "step 118000, train accuracy 0.74 , loss 220.511\n",
            "step 118100, train accuracy 0.74 , loss 656.745\n",
            "step 118200, train accuracy 0.77 , loss 776.726\n",
            "step 118300, train accuracy 0.78 , loss 435.182\n",
            "step 118400, train accuracy 0.67 , loss 593.223\n",
            "step 118500, train accuracy 0.83 , loss 835.401\n",
            "step 118600, train accuracy 0.66 , loss 246.77\n",
            "step 118700, train accuracy 0.77 , loss 379.06\n",
            "step 118800, train accuracy 0.7 , loss 246.241\n",
            "step 118900, train accuracy 0.78 , loss 588.007\n",
            "step 119000, train accuracy 0.86 , loss 182.51\n",
            "step 119100, train accuracy 0.79 , loss 620.246\n",
            "step 119200, train accuracy 0.77 , loss 184.048\n",
            "step 119300, train accuracy 0.72 , loss 201.573\n",
            "step 119400, train accuracy 0.76 , loss 112.567\n",
            "step 119500, train accuracy 0.79 , loss 558.209\n",
            "step 119600, train accuracy 0.67 , loss 514.026\n",
            "step 119700, train accuracy 0.8 , loss 181.487\n",
            "step 119800, train accuracy 0.86 , loss 568.873\n",
            "step 119900, train accuracy 0.78 , loss 876.257\n",
            "step 120000, train accuracy 0.81 , loss 465.88\n",
            "step 120100, train accuracy 0.68 , loss 748.973\n",
            "step 120200, train accuracy 0.76 , loss 208.128\n",
            "step 120300, train accuracy 0.81 , loss 728.788\n",
            "step 120400, train accuracy 0.69 , loss 610.025\n",
            "step 120500, train accuracy 0.82 , loss 297.499\n",
            "step 120600, train accuracy 0.83 , loss 679.453\n",
            "step 120700, train accuracy 0.82 , loss 142.4\n",
            "step 120800, train accuracy 0.74 , loss 530.937\n",
            "step 120900, train accuracy 0.77 , loss 535.764\n",
            "step 121000, train accuracy 0.73 , loss 632.767\n",
            "step 121100, train accuracy 0.82 , loss 599.757\n",
            "step 121200, train accuracy 0.7 , loss 231.192\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 121300, train accuracy 0.82 , loss 548.827\n",
            "step 121400, train accuracy 0.81 , loss 256.477\n",
            "step 121500, train accuracy 0.81 , loss 218.633\n",
            "step 121600, train accuracy 0.79 , loss 140.042\n",
            "step 121700, train accuracy 0.74 , loss 461.201\n",
            "step 121800, train accuracy 0.76 , loss 508.122\n",
            "step 121900, train accuracy 0.7 , loss 234.475\n",
            "step 122000, train accuracy 0.75 , loss 575.333\n",
            "step 122100, train accuracy 0.77 , loss 621.341\n",
            "step 122200, train accuracy 0.81 , loss 307.197\n",
            "step 122300, train accuracy 0.72 , loss 594.543\n",
            "step 122400, train accuracy 0.67 , loss 249.053\n",
            "step 122500, train accuracy 0.81 , loss 225.737\n",
            "step 122600, train accuracy 0.78 , loss 132.881\n",
            "step 122700, train accuracy 0.83 , loss 171.078\n",
            "step 122800, train accuracy 0.7 , loss 442.877\n",
            "step 122900, train accuracy 0.74 , loss 200.571\n",
            "step 123000, train accuracy 0.74 , loss 192.581\n",
            "step 123100, train accuracy 0.72 , loss 591.077\n",
            "step 123200, train accuracy 0.77 , loss 221.444\n",
            "step 123300, train accuracy 0.82 , loss 541.32\n",
            "step 123400, train accuracy 0.68 , loss 665.084\n",
            "step 123500, train accuracy 0.81 , loss 571.961\n",
            "step 123600, train accuracy 0.68 , loss 579.662\n",
            "step 123700, train accuracy 0.72 , loss 502.726\n",
            "step 123800, train accuracy 0.75 , loss 632.663\n",
            "step 123900, train accuracy 0.69 , loss 661.311\n",
            "step 124000, train accuracy 0.71 , loss 160.137\n",
            "step 124100, train accuracy 0.65 , loss 306.463\n",
            "step 124200, train accuracy 0.82 , loss 119.174\n",
            "step 124300, train accuracy 0.73 , loss 681.604\n",
            "step 124400, train accuracy 0.75 , loss 248.966\n",
            "step 124500, train accuracy 0.77 , loss 167.104\n",
            "step 124600, train accuracy 0.76 , loss 134.187\n",
            "step 124700, train accuracy 0.8 , loss 189.322\n",
            "step 124800, train accuracy 0.76 , loss 140.775\n",
            "step 124900, train accuracy 0.64 , loss 694.636\n",
            "step 125000, train accuracy 0.72 , loss 656.142\n",
            "step 125100, train accuracy 0.76 , loss 273.088\n",
            "step 125200, train accuracy 0.79 , loss 351.896\n",
            "step 125300, train accuracy 0.78 , loss 488.071\n",
            "step 125400, train accuracy 0.81 , loss 110.584\n",
            "step 125500, train accuracy 0.8 , loss 527.636\n",
            "step 125600, train accuracy 0.73 , loss 487.239\n",
            "step 125700, train accuracy 0.7 , loss 179.601\n",
            "step 125800, train accuracy 0.72 , loss 202.174\n",
            "step 125900, train accuracy 0.83 , loss 157.345\n",
            "step 126000, train accuracy 0.79 , loss 244.497\n",
            "step 126100, train accuracy 0.78 , loss 219.387\n",
            "step 126200, train accuracy 0.85 , loss 91.8641\n",
            "step 126300, train accuracy 0.75 , loss 599.777\n",
            "step 126400, train accuracy 0.8 , loss 213.395\n",
            "step 126500, train accuracy 0.78 , loss 213.125\n",
            "step 126600, train accuracy 0.76 , loss 392.271\n",
            "step 126700, train accuracy 0.78 , loss 189.163\n",
            "step 126800, train accuracy 0.84 , loss 608.705\n",
            "step 126900, train accuracy 0.78 , loss 137.588\n",
            "step 127000, train accuracy 0.78 , loss 575.622\n",
            "step 127100, train accuracy 0.7 , loss 599.908\n",
            "step 127200, train accuracy 0.82 , loss 119.774\n",
            "step 127300, train accuracy 0.7 , loss 788.572\n",
            "step 127400, train accuracy 0.75 , loss 181.155\n",
            "step 127500, train accuracy 0.76 , loss 210.293\n",
            "step 127600, train accuracy 0.83 , loss 719.733\n",
            "step 127700, train accuracy 0.81 , loss 577.033\n",
            "step 127800, train accuracy 0.73 , loss 312.72\n",
            "step 127900, train accuracy 0.87 , loss 199.227\n",
            "step 128000, train accuracy 0.84 , loss 593.135\n",
            "step 128100, train accuracy 0.77 , loss 582.986\n",
            "step 128200, train accuracy 0.77 , loss 304.203\n",
            "step 128300, train accuracy 0.75 , loss 485.052\n",
            "step 128400, train accuracy 0.93 , loss 83.6757\n",
            "step 128500, train accuracy 0.81 , loss 505.39\n",
            "step 128600, train accuracy 0.75 , loss 259.549\n",
            "step 128700, train accuracy 0.65 , loss 507.788\n",
            "step 128800, train accuracy 0.64 , loss 688.273\n",
            "step 128900, train accuracy 0.84 , loss 785.696\n",
            "step 129000, train accuracy 0.61 , loss 499.993\n",
            "step 129100, train accuracy 0.81 , loss 211.724\n",
            "step 129200, train accuracy 0.79 , loss 185.871\n",
            "step 129300, train accuracy 0.78 , loss 163.874\n",
            "step 129400, train accuracy 0.75 , loss 699.909\n",
            "step 129500, train accuracy 0.86 , loss 638.403\n",
            "step 129600, train accuracy 0.74 , loss 225.902\n",
            "step 129700, train accuracy 0.72 , loss 559.865\n",
            "step 129800, train accuracy 0.84 , loss 647.648\n",
            "step 129900, train accuracy 0.82 , loss 485.966\n",
            "step 130000, train accuracy 0.83 , loss 219.241\n",
            "step 130100, train accuracy 0.78 , loss 156.366\n",
            "step 130200, train accuracy 0.77 , loss 409.884\n",
            "step 130300, train accuracy 0.8 , loss 585.915\n",
            "step 130400, train accuracy 0.81 , loss 680.876\n",
            "step 130500, train accuracy 0.72 , loss 637.882\n",
            "step 130600, train accuracy 0.76 , loss 248.379\n",
            "step 130700, train accuracy 0.84 , loss 426.571\n",
            "step 130800, train accuracy 0.83 , loss 466.936\n",
            "step 130900, train accuracy 0.68 , loss 289.371\n",
            "step 131000, train accuracy 0.75 , loss 147.714\n",
            "step 131100, train accuracy 0.84 , loss 189.13\n",
            "step 131200, train accuracy 0.84 , loss 158.372\n",
            "step 131300, train accuracy 0.83 , loss 190.145\n",
            "step 131400, train accuracy 0.82 , loss 120.623\n",
            "step 131500, train accuracy 0.76 , loss 217.001\n",
            "step 131600, train accuracy 0.73 , loss 285.648\n",
            "step 131700, train accuracy 0.73 , loss 499.42\n",
            "step 131800, train accuracy 0.75 , loss 542.958\n",
            "step 131900, train accuracy 0.65 , loss 127.089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 132000, train accuracy 0.72 , loss 510.213\n",
            "step 132100, train accuracy 0.77 , loss 563.5\n",
            "step 132200, train accuracy 0.75 , loss 690.323\n",
            "step 132300, train accuracy 0.71 , loss 231.217\n",
            "step 132400, train accuracy 0.7 , loss 219.37\n",
            "step 132500, train accuracy 0.71 , loss 478.362\n",
            "step 132600, train accuracy 0.76 , loss 236.376\n",
            "step 132700, train accuracy 0.74 , loss 448.895\n",
            "step 132800, train accuracy 0.68 , loss 549.554\n",
            "step 132900, train accuracy 0.8 , loss 162.135\n",
            "step 133000, train accuracy 0.67 , loss 537.246\n",
            "step 133100, train accuracy 0.76 , loss 324.705\n",
            "step 133200, train accuracy 0.79 , loss 691.608\n",
            "step 133300, train accuracy 0.74 , loss 634.437\n",
            "step 133400, train accuracy 0.69 , loss 406.226\n",
            "step 133500, train accuracy 0.76 , loss 185.838\n",
            "step 133600, train accuracy 0.82 , loss 267.843\n",
            "step 133700, train accuracy 0.69 , loss 485.338\n",
            "step 133800, train accuracy 0.71 , loss 156.908\n",
            "step 133900, train accuracy 0.78 , loss 151.185\n",
            "step 134000, train accuracy 0.73 , loss 264.222\n",
            "step 134100, train accuracy 0.67 , loss 643.558\n",
            "step 134200, train accuracy 0.79 , loss 617.697\n",
            "step 134300, train accuracy 0.73 , loss 412.1\n",
            "step 134400, train accuracy 0.72 , loss 512.506\n",
            "step 134500, train accuracy 0.7 , loss 185.552\n",
            "step 134600, train accuracy 0.75 , loss 775.851\n",
            "step 134700, train accuracy 0.76 , loss 537.238\n",
            "step 134800, train accuracy 0.72 , loss 585.519\n",
            "step 134900, train accuracy 0.7 , loss 515.286\n",
            "step 135000, train accuracy 0.7 , loss 253.836\n",
            "step 135100, train accuracy 0.83 , loss 183.908\n",
            "step 135200, train accuracy 0.66 , loss 374.781\n",
            "step 135300, train accuracy 0.82 , loss 175.282\n",
            "step 135400, train accuracy 0.66 , loss 665.432\n",
            "step 135500, train accuracy 0.72 , loss 226.156\n",
            "step 135600, train accuracy 0.7 , loss 154.448\n",
            "step 135700, train accuracy 0.88 , loss 270.318\n",
            "step 135800, train accuracy 0.73 , loss 473.529\n",
            "step 135900, train accuracy 0.75 , loss 479.382\n",
            "step 136000, train accuracy 0.72 , loss 154.435\n",
            "step 136100, train accuracy 0.74 , loss 543.445\n",
            "step 136200, train accuracy 0.74 , loss 555.732\n",
            "step 136300, train accuracy 0.76 , loss 398.688\n",
            "step 136400, train accuracy 0.72 , loss 542.725\n",
            "step 136500, train accuracy 0.77 , loss 199.164\n",
            "step 136600, train accuracy 0.77 , loss 566.001\n",
            "step 136700, train accuracy 0.67 , loss 670.467\n",
            "step 136800, train accuracy 0.78 , loss 423.458\n",
            "step 136900, train accuracy 0.68 , loss 471.229\n",
            "step 137000, train accuracy 0.73 , loss 275.491\n",
            "step 137100, train accuracy 0.82 , loss 166.129\n",
            "step 137200, train accuracy 0.73 , loss 648.502\n",
            "step 137300, train accuracy 0.71 , loss 354.888\n",
            "step 137400, train accuracy 0.59 , loss 498.109\n",
            "step 137500, train accuracy 0.71 , loss 558.297\n",
            "step 137600, train accuracy 0.74 , loss 375.125\n",
            "step 137700, train accuracy 0.76 , loss 411.643\n",
            "step 137800, train accuracy 0.75 , loss 512.453\n",
            "step 137900, train accuracy 0.66 , loss 308.164\n",
            "step 138000, train accuracy 0.76 , loss 247.046\n",
            "step 138100, train accuracy 0.76 , loss 403.995\n",
            "step 138200, train accuracy 0.68 , loss 331.35\n",
            "step 138300, train accuracy 0.76 , loss 445.318\n",
            "step 138400, train accuracy 0.77 , loss 432.941\n",
            "step 138500, train accuracy 0.69 , loss 510.531\n",
            "step 138600, train accuracy 0.68 , loss 564.886\n",
            "step 138700, train accuracy 0.56 , loss 355.571\n",
            "step 138800, train accuracy 0.7 , loss 250.139\n",
            "step 138900, train accuracy 0.63 , loss 541.274\n",
            "step 139000, train accuracy 0.74 , loss 268.249\n",
            "step 139100, train accuracy 0.73 , loss 459.166\n",
            "step 139200, train accuracy 0.7 , loss 565.468\n",
            "step 139300, train accuracy 0.71 , loss 565.151\n",
            "step 139400, train accuracy 0.76 , loss 235.714\n",
            "step 139500, train accuracy 0.67 , loss 182.054\n",
            "step 139600, train accuracy 0.65 , loss 402.221\n",
            "step 139700, train accuracy 0.76 , loss 270.102\n",
            "step 139800, train accuracy 0.68 , loss 302.218\n",
            "step 139900, train accuracy 0.7 , loss 211.652\n",
            "step 140000, train accuracy 0.73 , loss 209.021\n",
            "step 140100, train accuracy 0.72 , loss 438.529\n",
            "step 140200, train accuracy 0.66 , loss 281.201\n",
            "step 140300, train accuracy 0.75 , loss 286.211\n",
            "step 140400, train accuracy 0.75 , loss 150.789\n",
            "step 140500, train accuracy 0.71 , loss 508.032\n",
            "step 140600, train accuracy 0.75 , loss 164.02\n",
            "step 140700, train accuracy 0.63 , loss 172.469\n",
            "step 140800, train accuracy 0.77 , loss 445.796\n",
            "step 140900, train accuracy 0.71 , loss 349.906\n",
            "step 141000, train accuracy 0.66 , loss 513.055\n",
            "step 141100, train accuracy 0.72 , loss 542.881\n",
            "step 141200, train accuracy 0.79 , loss 264.109\n",
            "step 141300, train accuracy 0.62 , loss 512.555\n",
            "step 141400, train accuracy 0.68 , loss 250.554\n",
            "step 141500, train accuracy 0.7 , loss 336.606\n",
            "step 141600, train accuracy 0.68 , loss 449.751\n",
            "step 141700, train accuracy 0.76 , loss 681.477\n",
            "step 141800, train accuracy 0.81 , loss 175.157\n",
            "step 141900, train accuracy 0.77 , loss 214.954\n",
            "step 142000, train accuracy 0.76 , loss 353.564\n",
            "step 142100, train accuracy 0.73 , loss 263.16\n",
            "step 142200, train accuracy 0.75 , loss 558.005\n",
            "step 142300, train accuracy 0.64 , loss 391.095\n",
            "step 142400, train accuracy 0.75 , loss 432.336\n",
            "step 142500, train accuracy 0.61 , loss 485.312\n",
            "step 142600, train accuracy 0.54 , loss 403.279\n",
            "step 142700, train accuracy 0.72 , loss 259.287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 142800, train accuracy 0.84 , loss 199.07\n",
            "step 142900, train accuracy 0.78 , loss 267.057\n",
            "step 143000, train accuracy 0.67 , loss 207.531\n",
            "step 143100, train accuracy 0.69 , loss 570.487\n",
            "step 143200, train accuracy 0.74 , loss 579.976\n",
            "step 143300, train accuracy 0.65 , loss 261.186\n",
            "step 143400, train accuracy 0.84 , loss 514.636\n",
            "step 143500, train accuracy 0.71 , loss 164.868\n",
            "step 143600, train accuracy 0.78 , loss 535.328\n",
            "step 143700, train accuracy 0.78 , loss 255.901\n",
            "step 143800, train accuracy 0.66 , loss 195.737\n",
            "step 143900, train accuracy 0.73 , loss 263.075\n",
            "step 144000, train accuracy 0.84 , loss 564.833\n",
            "step 144100, train accuracy 0.78 , loss 114.266\n",
            "step 144200, train accuracy 0.73 , loss 526.768\n",
            "step 144300, train accuracy 0.74 , loss 236.317\n",
            "step 144400, train accuracy 0.77 , loss 551.556\n",
            "step 144500, train accuracy 0.74 , loss 251.822\n",
            "step 144600, train accuracy 0.7 , loss 493.171\n",
            "step 144700, train accuracy 0.75 , loss 509.823\n",
            "step 144800, train accuracy 0.69 , loss 273.234\n",
            "step 144900, train accuracy 0.62 , loss 622.255\n",
            "step 145000, train accuracy 0.81 , loss 336.681\n",
            "step 145100, train accuracy 0.74 , loss 572.266\n",
            "step 145200, train accuracy 0.72 , loss 296.268\n",
            "step 145300, train accuracy 0.7 , loss 164.751\n",
            "step 145400, train accuracy 0.73 , loss 250.372\n",
            "step 145500, train accuracy 0.78 , loss 382.156\n",
            "step 145600, train accuracy 0.79 , loss 557.084\n",
            "step 145700, train accuracy 0.78 , loss 516.326\n",
            "step 145800, train accuracy 0.72 , loss 245.059\n",
            "step 145900, train accuracy 0.75 , loss 197.45\n",
            "step 146000, train accuracy 0.57 , loss 396.843\n",
            "step 146100, train accuracy 0.81 , loss 144.62\n",
            "step 146200, train accuracy 0.8 , loss 154.155\n",
            "step 146300, train accuracy 0.71 , loss 188.451\n",
            "step 146400, train accuracy 0.66 , loss 546.021\n",
            "step 146500, train accuracy 0.8 , loss 480.308\n",
            "step 146600, train accuracy 0.85 , loss 150.713\n",
            "step 146700, train accuracy 0.74 , loss 512.409\n",
            "step 146800, train accuracy 0.69 , loss 462.981\n",
            "step 146900, train accuracy 0.82 , loss 270.557\n",
            "step 147000, train accuracy 0.84 , loss 196.182\n",
            "step 147100, train accuracy 0.82 , loss 433.552\n",
            "step 147200, train accuracy 0.88 , loss 570.126\n",
            "step 147300, train accuracy 0.77 , loss 160.226\n",
            "step 147400, train accuracy 0.7 , loss 277.413\n",
            "step 147500, train accuracy 0.8 , loss 605.183\n",
            "step 147600, train accuracy 0.67 , loss 551.702\n",
            "step 147700, train accuracy 0.7 , loss 105.782\n",
            "step 147800, train accuracy 0.74 , loss 157.925\n",
            "step 147900, train accuracy 0.71 , loss 442.772\n",
            "step 148000, train accuracy 0.78 , loss 367.721\n",
            "step 148100, train accuracy 0.81 , loss 180.513\n",
            "step 148200, train accuracy 0.78 , loss 529.235\n",
            "step 148300, train accuracy 0.69 , loss 196.478\n",
            "step 148400, train accuracy 0.77 , loss 118.996\n",
            "step 148500, train accuracy 0.74 , loss 154.434\n",
            "step 148600, train accuracy 0.73 , loss 157.086\n",
            "step 148700, train accuracy 0.82 , loss 94.2435\n",
            "step 148800, train accuracy 0.83 , loss 139.448\n",
            "step 148900, train accuracy 0.87 , loss 148.018\n",
            "step 149000, train accuracy 0.83 , loss 638.101\n",
            "step 149100, train accuracy 0.81 , loss 610.096\n",
            "step 149200, train accuracy 0.81 , loss 448.539\n",
            "step 149300, train accuracy 0.91 , loss 151.182\n",
            "step 149400, train accuracy 0.75 , loss 591.488\n",
            "step 149500, train accuracy 0.74 , loss 608.771\n",
            "step 149600, train accuracy 0.74 , loss 517.796\n",
            "step 149700, train accuracy 0.79 , loss 87.2992\n",
            "step 149800, train accuracy 0.75 , loss 131.908\n",
            "step 149900, train accuracy 0.7 , loss 472.79\n",
            "step 150000, train accuracy 0.73 , loss 574.236\n",
            "step 150100, train accuracy 0.67 , loss 445.209\n",
            "step 150200, train accuracy 0.8 , loss 628.965\n",
            "step 150300, train accuracy 0.79 , loss 364.964\n",
            "step 150400, train accuracy 0.71 , loss 558.49\n",
            "step 150500, train accuracy 0.77 , loss 567.559\n",
            "step 150600, train accuracy 0.77 , loss 177.746\n",
            "step 150700, train accuracy 0.7 , loss 176.692\n",
            "step 150800, train accuracy 0.67 , loss 459.374\n",
            "step 150900, train accuracy 0.75 , loss 453.139\n",
            "step 151000, train accuracy 0.7 , loss 244.842\n",
            "step 151100, train accuracy 0.73 , loss 494.56\n",
            "step 151200, train accuracy 0.76 , loss 461.403\n",
            "step 151300, train accuracy 0.75 , loss 145.28\n",
            "step 151400, train accuracy 0.79 , loss 437.38\n",
            "step 151500, train accuracy 0.77 , loss 615.236\n",
            "step 151600, train accuracy 0.72 , loss 520.813\n",
            "step 151700, train accuracy 0.7 , loss 299.654\n",
            "step 151800, train accuracy 0.78 , loss 450.795\n",
            "step 151900, train accuracy 0.66 , loss 352.279\n",
            "step 152000, train accuracy 0.82 , loss 424.231\n",
            "step 152100, train accuracy 0.79 , loss 205.563\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3250670b3b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-3250670b3b1a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "pWJI2UdMhpca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c3ae05f1-05a3-4062-8434-cb66b7ba1688"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tf8ulIAIhqep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42a0768e-8861-445b-a849-aae61d9369b2"
      },
      "cell_type": "code",
      "source": [
        "cd log"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FNyPUMTPhsIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "13643e20-e271-4adb-a4ed-7c5fd867de61"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t       model.ckpt-140000.index\r\n",
            "model.ckpt-130000.data-00000-of-00001  model.ckpt-140000.meta\r\n",
            "model.ckpt-130000.index\t\t       model.ckpt-145000.data-00000-of-00001\r\n",
            "model.ckpt-130000.meta\t\t       model.ckpt-145000.index\r\n",
            "model.ckpt-135000.data-00000-of-00001  model.ckpt-145000.meta\r\n",
            "model.ckpt-135000.index\t\t       model.ckpt-150000.data-00000-of-00001\r\n",
            "model.ckpt-135000.meta\t\t       model.ckpt-150000.index\r\n",
            "model.ckpt-140000.data-00000-of-00001  model.ckpt-150000.meta\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_JjkOE0mhtrh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "795ecbd2-4e6f-45be-84b4-c211855e8ac8"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uCrvC4PFiL2I",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "83aeee46-191d-4b66-d35c-4221ffd99378"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb8d69cd-4d50-4c05-8cad-8b726a21a492\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bb8d69cd-4d50-4c05-8cad-8b726a21a492\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wang_data.csv to wang_data.csv\n",
            "Saving wang_data_test.csv to wang_data_test.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AHFLbrCEm05y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8507
        },
        "outputId": "eee727bd-09ef-4951-ee8e-ead49ff7f601"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "from sklearn import preprocessing\n",
        "\n",
        "num_class = 2\n",
        "batch_size = 20\n",
        "train_path = r\"wang_data.csv\"\n",
        "test_path = r\"wang_data_test.csv\"\n",
        "learning_rate = 0.00001\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "size = 37\n",
        "log_path = r\"./log/\"\n",
        "\n",
        "\n",
        "def readData(path):\n",
        "    whole_data = pd.read_csv(path, encoding='utf-8')\n",
        "    whole_data = whole_data.fillna(0)\n",
        "    whole_list = np.array(whole_data)\n",
        "    for i in range(len(whole_list)):\n",
        "        for temp in range(len(whole_list[i])):\n",
        "            if whole_list[i][temp] == \" \":\n",
        "                whole_list[i][temp] = 0\n",
        "    # print(\"转换前：\", whole_list)\n",
        "    whole_list = np.array(whole_list, dtype=\"float\")\n",
        "    # print(whole_list)\n",
        "    return whole_list\n",
        "\n",
        "\n",
        "def makeData(data, flag):\n",
        "    x = []\n",
        "    y = []\n",
        "    ran = []\n",
        "    # print(len(data))\n",
        "    # print(len(data[1480]))\n",
        "    # print(data)\n",
        "    if flag == \"train\":\n",
        "        for i in range(batch_size):\n",
        "            index = random.randint(0, 6384)\n",
        "            # print(\"test data len\", len(data))\n",
        "            row = data[index]\n",
        "            label = [int(row[37])]\n",
        "            y.append(label)\n",
        "            row = np.delete(row, 37)\n",
        "            x.append(row)\n",
        "            ran.append(index)\n",
        "    else:\n",
        "        for i in range(batch_size):\n",
        "            index = random.randint(0, 66)\n",
        "            # print(\"test data len\", len(data))\n",
        "            row = data[index]\n",
        "            label = [int(row[37])]\n",
        "            y.append(label)\n",
        "            row = np.delete(row, 37)\n",
        "            x.append(row)\n",
        "            ran.append(index)\n",
        "    # print(label)\n",
        "    # print(\"lenx:\",len(x))\n",
        "    # print(\"len x1:\",len(x[1]))\n",
        "    # x = tf.reshape(x, shape=[batch_size, size])\n",
        "    # label = tf.reshape(label, shape=[batch_size, 2])\n",
        "\n",
        "    return x, y, ran\n",
        "\n",
        "\n",
        "def getWeight(shape):\n",
        "    w = tf.truncated_normal(shape, 0.1)\n",
        "    return tf.Variable(w)\n",
        "\n",
        "\n",
        "def getBias(shape):\n",
        "    b = tf.constant(0.1, shape=shape)\n",
        "    return tf.Variable(b)\n",
        "\n",
        "\n",
        "def fc(input, keep_prob):\n",
        "    fc1_w = getWeight([size, 128])\n",
        "    fc1_b = getBias([128])\n",
        "    fc1 = tf.nn.relu(tf.matmul(input, fc1_w) + fc1_b)\n",
        "    h_fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
        "    fc2_w = getWeight([128, 2])\n",
        "    fc2_b = getBias([2])\n",
        "    fc2 = tf.matmul(h_fc1_drop, fc2_w) + fc2_b\n",
        "\n",
        "    return fc2, fc1_w, fc2_w\n",
        "\n",
        "\n",
        "def cross_entropy(fc_result, label):\n",
        "    label = tf.one_hot(label, depth=num_class)\n",
        "    return tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=fc_result, labels=label))\n",
        "\n",
        "\n",
        "def train():\n",
        "    x_ = tf.placeholder(shape=[batch_size, size], dtype=\"float\")\n",
        "    y_ = tf.placeholder(shape=[batch_size, 1], dtype=\"int32\")\n",
        "    keep_prob = tf.placeholder(\"float\")\n",
        "\n",
        "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
        "    logits, fc1, fc2 = fc(x_, keep_prob)\n",
        "    loss = cross_entropy(logits, y_)\n",
        "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "    train_op = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
        "    init = tf.global_variables_initializer()\n",
        "    sess = tf.Session(config=config)\n",
        "    sess.run(init)\n",
        "    saver = tf.train.Saver(tf.global_variables())\n",
        "    whole_data = readData(train_path)\n",
        "    test_data = readData(test_path)\n",
        "    # whole_data = sess.run(read_data)\n",
        "    for i in range(3000000):\n",
        "        if i % 100 == 0:\n",
        "            x, y, indexs = makeData(whole_data, \"train\")\n",
        "            test_x, test_y, test_index = makeData(test_data, \"test\")\n",
        "\n",
        "            #归一化\n",
        "            min_max_scaler = preprocessing.MinMaxScaler()\n",
        "            x = min_max_scaler.fit_transform(x)\n",
        "\n",
        "            # 标准化\n",
        "            ss_x = StandardScaler()\n",
        "            ss_y = StandardScaler()\n",
        "            x = ss_x.fit_transform(x)\n",
        "            y = ss_y.fit_transform(y)\n",
        "            #print(\"x:\", x)\n",
        "            test_x = ss_x.transform(test_x)\n",
        "            #print(\"test x:\", x)\n",
        "            test_y = ss_y.transform(test_y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # x = tf.reshape(x, shape=[batch_size, size])\n",
        "            # x = tf.cast(x, dtype=tf.float32)\n",
        "            train_accuracy = sess.run(accuracy, feed_dict={x_: test_x, y_: test_y, keep_prob: 1})\n",
        "            lo = sess.run(loss, feed_dict={x_: x, y_: y, keep_prob: 1})\n",
        "            # f1w = sess.run(fc1, feed_dict={x_: x, y_: y, keep_prob: 1})\n",
        "            # f2w = sess.run(fc2, feed_dict={x_: x, y_: y, keep_prob: 1})\n",
        "            # print(\"f1:\",f1w,\"\\n\",\"f2:\",f2w)\n",
        "            print(\"step %d, train accuracy %g , loss %g\" % (i, train_accuracy, lo))\n",
        "            # print(indexs)\n",
        "        if i % 5000 == 0 and i != 0:\n",
        "            save_path = os.path.join(log_path, \"model.ckpt\")\n",
        "            saver.save(sess, save_path, global_step=i)\n",
        "\n",
        "        sess.run(train_op, feed_dict={x_: x, y_: y, keep_prob: 0.4})\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0, train accuracy 0.3 , loss 158.789\n",
            "step 100, train accuracy 0 , loss 279.095\n",
            "step 200, train accuracy 0.4 , loss 151.713\n",
            "step 300, train accuracy 0.4 , loss 160.283\n",
            "step 400, train accuracy 0.5 , loss 44.5085\n",
            "step 500, train accuracy 0.25 , loss 216.754\n",
            "step 600, train accuracy 0.4 , loss 112.508\n",
            "step 700, train accuracy 0.6 , loss 60.7116\n",
            "step 800, train accuracy 0.6 , loss 286.789\n",
            "step 900, train accuracy 0.6 , loss 389.322\n",
            "step 1000, train accuracy 0.75 , loss 131.933\n",
            "step 1100, train accuracy 0.65 , loss 56.9048\n",
            "step 1200, train accuracy 0.55 , loss 121.206\n",
            "step 1300, train accuracy 0.65 , loss 150.766\n",
            "step 1400, train accuracy 0.55 , loss 88.835\n",
            "step 1500, train accuracy 0.8 , loss 140.348\n",
            "step 1600, train accuracy 0.5 , loss 119.979\n",
            "step 1700, train accuracy 0.75 , loss 75.5894\n",
            "step 1800, train accuracy 0.75 , loss 192.416\n",
            "step 1900, train accuracy 0.65 , loss 157.665\n",
            "step 2000, train accuracy 0.75 , loss 273.776\n",
            "step 2100, train accuracy 0.7 , loss 74.6349\n",
            "step 2200, train accuracy 0.7 , loss 213.175\n",
            "step 2300, train accuracy 0.65 , loss 160.58\n",
            "step 2400, train accuracy 0.55 , loss 110.994\n",
            "step 2500, train accuracy 0.7 , loss 84.4446\n",
            "step 2600, train accuracy 0.6 , loss 238.64\n",
            "step 2700, train accuracy 0.5 , loss 93.5203\n",
            "step 2800, train accuracy 0.4 , loss 95.9952\n",
            "step 2900, train accuracy 0.3 , loss 49.4382\n",
            "step 3000, train accuracy 0.45 , loss 97.8873\n",
            "step 3100, train accuracy 0.5 , loss 161.593\n",
            "step 3200, train accuracy 0.7 , loss 51.9307\n",
            "step 3300, train accuracy 0.5 , loss 0.47114\n",
            "step 3400, train accuracy 0.4 , loss 71.3208\n",
            "step 3500, train accuracy 0.05 , loss 3.17364\n",
            "step 3600, train accuracy 0.05 , loss 316.192\n",
            "step 3700, train accuracy 0.2 , loss 312.465\n",
            "step 3800, train accuracy 0.1 , loss 148.79\n",
            "step 3900, train accuracy 0.55 , loss 41.0667\n",
            "step 4000, train accuracy 0.55 , loss 59.8596\n",
            "step 4100, train accuracy 0.4 , loss 178.252\n",
            "step 4200, train accuracy 0.35 , loss 163.695\n",
            "step 4300, train accuracy 0.7 , loss 15.364\n",
            "step 4400, train accuracy 0.6 , loss 151.75\n",
            "step 4500, train accuracy 0.5 , loss 97.1712\n",
            "step 4600, train accuracy 0.45 , loss 65.2645\n",
            "step 4700, train accuracy 0.55 , loss 75.3086\n",
            "step 4800, train accuracy 0.7 , loss 129.194\n",
            "step 4900, train accuracy 0.75 , loss 128.685\n",
            "step 5000, train accuracy 0.5 , loss 53.4475\n",
            "step 5100, train accuracy 0.85 , loss 77.0597\n",
            "step 5200, train accuracy 0.6 , loss 60.1962\n",
            "step 5300, train accuracy 0.65 , loss 33.1523\n",
            "step 5400, train accuracy 0.35 , loss 151.155\n",
            "step 5500, train accuracy 0.7 , loss 154.958\n",
            "step 5600, train accuracy 0.35 , loss 95.3005\n",
            "step 5700, train accuracy 0.5 , loss 93.7998\n",
            "step 5800, train accuracy 0.8 , loss 101.417\n",
            "step 5900, train accuracy 0.95 , loss 61.0417\n",
            "step 6000, train accuracy 0.6 , loss 27.7252\n",
            "step 6100, train accuracy 0.55 , loss 137.606\n",
            "step 6200, train accuracy 0.75 , loss 16.6642\n",
            "step 6300, train accuracy 0.75 , loss 42.7285\n",
            "step 6400, train accuracy 0.6 , loss 54.2248\n",
            "step 6500, train accuracy 0.3 , loss 118.927\n",
            "step 6600, train accuracy 0.7 , loss 61.5929\n",
            "step 6700, train accuracy 0.65 , loss 74.6245\n",
            "step 6800, train accuracy 0.55 , loss 25.2877\n",
            "step 6900, train accuracy 0.45 , loss 49.6892\n",
            "step 7000, train accuracy 0.7 , loss 55.6097\n",
            "step 7100, train accuracy 0.5 , loss 174.769\n",
            "step 7200, train accuracy 0.7 , loss 98.8006\n",
            "step 7300, train accuracy 0.8 , loss 58.1215\n",
            "step 7400, train accuracy 0.7 , loss 99.4112\n",
            "step 7500, train accuracy 0.6 , loss 11.3365\n",
            "step 7600, train accuracy 0.45 , loss 56.8768\n",
            "step 7700, train accuracy 0.5 , loss 29.668\n",
            "step 7800, train accuracy 0.05 , loss 294.729\n",
            "step 7900, train accuracy 0.75 , loss 85.1044\n",
            "step 8000, train accuracy 0.35 , loss 139.455\n",
            "step 8100, train accuracy 0.5 , loss 54.5721\n",
            "step 8200, train accuracy 0.4 , loss 70.1543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 8300, train accuracy 0.7 , loss 126.751\n",
            "step 8400, train accuracy 0.7 , loss 60.053\n",
            "step 8500, train accuracy 0.65 , loss 81.7669\n",
            "step 8600, train accuracy 0.55 , loss 52.3967\n",
            "step 8700, train accuracy 0.5 , loss 25.8524\n",
            "step 8800, train accuracy 0.8 , loss 49.0759\n",
            "step 8900, train accuracy 0.45 , loss 53.7114\n",
            "step 9000, train accuracy 0.7 , loss 60.0229\n",
            "step 9100, train accuracy 0.35 , loss 42.4289\n",
            "step 9200, train accuracy 0.65 , loss 38.3099\n",
            "step 9300, train accuracy 0.9 , loss 22.3229\n",
            "step 9400, train accuracy 0.95 , loss 10.0543\n",
            "step 9500, train accuracy 0.7 , loss 12.1124\n",
            "step 9600, train accuracy 0.55 , loss 127.316\n",
            "step 9700, train accuracy 0.6 , loss 46.2457\n",
            "step 9800, train accuracy 0.75 , loss 37.2549\n",
            "step 9900, train accuracy 0.75 , loss 89.723\n",
            "step 10000, train accuracy 0.55 , loss 61.1568\n",
            "step 10100, train accuracy 0.75 , loss 67.1887\n",
            "step 10200, train accuracy 0.9 , loss 9.03643\n",
            "step 10300, train accuracy 0.55 , loss 11.0619\n",
            "step 10400, train accuracy 0.85 , loss 4.59241\n",
            "step 10500, train accuracy 0.7 , loss 157.047\n",
            "step 10600, train accuracy 0.75 , loss 69.3958\n",
            "step 10700, train accuracy 0.8 , loss 37.5601\n",
            "step 10800, train accuracy 0.8 , loss 17.1235\n",
            "step 10900, train accuracy 0.6 , loss 48.61\n",
            "step 11000, train accuracy 0.8 , loss 10.005\n",
            "step 11100, train accuracy 0.9 , loss 65.8165\n",
            "step 11200, train accuracy 0.6 , loss 112.252\n",
            "step 11300, train accuracy 0.9 , loss 47.6272\n",
            "step 11400, train accuracy 0.8 , loss 20.7573\n",
            "step 11500, train accuracy 0.8 , loss 21.8059\n",
            "step 11600, train accuracy 0.8 , loss 28.9929\n",
            "step 11700, train accuracy 0.9 , loss 46.2989\n",
            "step 11800, train accuracy 0.95 , loss 127.26\n",
            "step 11900, train accuracy 0.8 , loss 76.7722\n",
            "step 12000, train accuracy 0.65 , loss 61.4805\n",
            "step 12100, train accuracy 0.6 , loss 22.7934\n",
            "step 12200, train accuracy 0.75 , loss 16.4162\n",
            "step 12300, train accuracy 0.85 , loss 31.8569\n",
            "step 12400, train accuracy 0.6 , loss 25.7481\n",
            "step 12500, train accuracy 0.85 , loss 26.7595\n",
            "step 12600, train accuracy 0.95 , loss 105.312\n",
            "step 12700, train accuracy 0.6 , loss 105.062\n",
            "step 12800, train accuracy 0.7 , loss 23.6683\n",
            "step 12900, train accuracy 0.8 , loss 31.0068\n",
            "step 13000, train accuracy 0.3 , loss 113.608\n",
            "step 13100, train accuracy 0.55 , loss 33.4708\n",
            "step 13200, train accuracy 0.5 , loss 128.493\n",
            "step 13300, train accuracy 0.8 , loss 57.4436\n",
            "step 13400, train accuracy 0.8 , loss 35.5244\n",
            "step 13500, train accuracy 0.5 , loss 38.3597\n",
            "step 13600, train accuracy 0.75 , loss 51.7799\n",
            "step 13700, train accuracy 0.75 , loss 32.11\n",
            "step 13800, train accuracy 0.75 , loss 27.6575\n",
            "step 13900, train accuracy 0.7 , loss 51.5236\n",
            "step 14000, train accuracy 0.65 , loss 93.4332\n",
            "step 14100, train accuracy 0.75 , loss 49.2449\n",
            "step 14200, train accuracy 0.75 , loss 40.8685\n",
            "step 14300, train accuracy 0.75 , loss 38.5352\n",
            "step 14400, train accuracy 0.75 , loss 6.87523\n",
            "step 14500, train accuracy 0.7 , loss 29.1836\n",
            "step 14600, train accuracy 0.9 , loss 1.0382\n",
            "step 14700, train accuracy 0.85 , loss 151.282\n",
            "step 14800, train accuracy 0.5 , loss 67.2136\n",
            "step 14900, train accuracy 0.95 , loss 17.0631\n",
            "step 15000, train accuracy 0.75 , loss 20.0826\n",
            "step 15100, train accuracy 0.75 , loss 16.6131\n",
            "step 15200, train accuracy 0.95 , loss 92.2139\n",
            "step 15300, train accuracy 0.45 , loss 19.9437\n",
            "step 15400, train accuracy 0.65 , loss 15.4916\n",
            "step 15500, train accuracy 0.95 , loss 55.6112\n",
            "step 15600, train accuracy 0.9 , loss 15.5953\n",
            "step 15700, train accuracy 0.8 , loss 100.511\n",
            "step 15800, train accuracy 0.9 , loss 32.2669\n",
            "step 15900, train accuracy 0.55 , loss 34.0567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 16000, train accuracy 0.05 , loss 53.14\n",
            "step 16100, train accuracy 0.7 , loss 19.0423\n",
            "step 16200, train accuracy 0.6 , loss 50.3919\n",
            "step 16300, train accuracy 0.85 , loss 17.185\n",
            "step 16400, train accuracy 0.8 , loss 48.7692\n",
            "step 16500, train accuracy 0.6 , loss 41.6118\n",
            "step 16600, train accuracy 0.8 , loss 21.5313\n",
            "step 16700, train accuracy 0.75 , loss 53.7558\n",
            "step 16800, train accuracy 0 , loss 53.7494\n",
            "step 16900, train accuracy 0.6 , loss 27.2012\n",
            "step 17000, train accuracy 0.45 , loss 31.2228\n",
            "step 17100, train accuracy 0.35 , loss 21.2704\n",
            "step 17200, train accuracy 0.35 , loss 1.87574\n",
            "step 17300, train accuracy 0.35 , loss 48.8713\n",
            "step 17400, train accuracy 0.7 , loss 12.7957\n",
            "step 17500, train accuracy 0.9 , loss 18.1474\n",
            "step 17600, train accuracy 0.7 , loss 40.8033\n",
            "step 17700, train accuracy 0.9 , loss 75.2539\n",
            "step 17800, train accuracy 0.5 , loss 39.0319\n",
            "step 17900, train accuracy 0.65 , loss 14.2514\n",
            "step 18000, train accuracy 0.75 , loss 38.146\n",
            "step 18100, train accuracy 0.8 , loss 22.8103\n",
            "step 18200, train accuracy 0.9 , loss 4.00444\n",
            "step 18300, train accuracy 0.95 , loss 12.3283\n",
            "step 18400, train accuracy 0.9 , loss 10.8918\n",
            "step 18500, train accuracy 0.95 , loss 31.9575\n",
            "step 18600, train accuracy 1 , loss 31.5782\n",
            "step 18700, train accuracy 0.9 , loss 34.3447\n",
            "step 18800, train accuracy 0.7 , loss 50.1494\n",
            "step 18900, train accuracy 0.75 , loss 52.2857\n",
            "step 19000, train accuracy 1 , loss 28.7383\n",
            "step 19100, train accuracy 0.45 , loss 43.7279\n",
            "step 19200, train accuracy 0.9 , loss 11.7002\n",
            "step 19300, train accuracy 0.65 , loss 35.6445\n",
            "step 19400, train accuracy 0 , loss 98.2424\n",
            "step 19500, train accuracy 0.7 , loss 16.5195\n",
            "step 19600, train accuracy 0.45 , loss 17.5909\n",
            "step 19700, train accuracy 0.75 , loss 3.59333\n",
            "step 19800, train accuracy 0.5 , loss 11.2078\n",
            "step 19900, train accuracy 0.5 , loss 13.5176\n",
            "step 20000, train accuracy 0.4 , loss 29.0913\n",
            "step 20100, train accuracy 0 , loss 109.195\n",
            "step 20200, train accuracy 0.85 , loss 13.0275\n",
            "step 20300, train accuracy 0.9 , loss 40.2498\n",
            "step 20400, train accuracy 1 , loss 10.0776\n",
            "step 20500, train accuracy 0.9 , loss 39.2144\n",
            "step 20600, train accuracy 0 , loss 1.91624\n",
            "step 20700, train accuracy 0.15 , loss 59.2377\n",
            "step 20800, train accuracy 0.85 , loss 2.33948\n",
            "step 20900, train accuracy 0.95 , loss 16.6376\n",
            "step 21000, train accuracy 1 , loss 19.3029\n",
            "step 21100, train accuracy 0.9 , loss 2.54304\n",
            "step 21200, train accuracy 1 , loss 14.5216\n",
            "step 21300, train accuracy 1 , loss 55.8154\n",
            "step 21400, train accuracy 1 , loss 21.6027\n",
            "step 21500, train accuracy 0.5 , loss 9.53316\n",
            "step 21600, train accuracy 0.85 , loss 30.4235\n",
            "step 21700, train accuracy 0.95 , loss 18.9399\n",
            "step 21800, train accuracy 0.95 , loss 14.7881\n",
            "step 21900, train accuracy 1 , loss 38.7316\n",
            "step 22000, train accuracy 0.95 , loss 33.2073\n",
            "step 22100, train accuracy 0 , loss 1.48819\n",
            "step 22200, train accuracy 0 , loss 94.5749\n",
            "step 22300, train accuracy 0.8 , loss 5.22494\n",
            "step 22400, train accuracy 0 , loss 82.6605\n",
            "step 22500, train accuracy 0.9 , loss 32.9705\n",
            "step 22600, train accuracy 0.55 , loss 7.807\n",
            "step 22700, train accuracy 0.7 , loss 16.1401\n",
            "step 22800, train accuracy 0.9 , loss 37.8725\n",
            "step 22900, train accuracy 1 , loss 14.579\n",
            "step 23000, train accuracy 0 , loss 13.7459\n",
            "step 23100, train accuracy 0.85 , loss 46.8403\n",
            "step 23200, train accuracy 0.85 , loss 22.5125\n",
            "step 23300, train accuracy 0.85 , loss 19.6376\n",
            "step 23400, train accuracy 0.9 , loss 23.6351\n",
            "step 23500, train accuracy 0.9 , loss 17.8668\n",
            "step 23600, train accuracy 0.9 , loss 22.3426\n",
            "step 23700, train accuracy 0 , loss 54.4902\n",
            "step 23800, train accuracy 0.8 , loss 9.5083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 23900, train accuracy 0.7 , loss 14.4206\n",
            "step 24000, train accuracy 0.8 , loss 25.9849\n",
            "step 24100, train accuracy 0.65 , loss 21.3366\n",
            "step 24200, train accuracy 0.75 , loss 5.99061\n",
            "step 24300, train accuracy 0.9 , loss 5.84928\n",
            "step 24400, train accuracy 1 , loss 26.658\n",
            "step 24500, train accuracy 0 , loss 20.4145\n",
            "step 24600, train accuracy 0.3 , loss 32.6322\n",
            "step 24700, train accuracy 1 , loss 19.0693\n",
            "step 24800, train accuracy 0 , loss 57.9257\n",
            "step 24900, train accuracy 1 , loss 17.9827\n",
            "step 25000, train accuracy 1 , loss 7.56997\n",
            "step 25100, train accuracy 0.95 , loss 25.7983\n",
            "step 25200, train accuracy 0.9 , loss 9.19616\n",
            "step 25300, train accuracy 1 , loss 20.5459\n",
            "step 25400, train accuracy 0 , loss 61.3153\n",
            "step 25500, train accuracy 1 , loss 10.4643\n",
            "step 25600, train accuracy 1 , loss 15.8911\n",
            "step 25700, train accuracy 1 , loss 14.4646\n",
            "step 25800, train accuracy 1 , loss 19.2644\n",
            "step 25900, train accuracy 0 , loss 1.58976\n",
            "step 26000, train accuracy 0 , loss 67.9522\n",
            "step 26100, train accuracy 0.85 , loss 6.99105\n",
            "step 26200, train accuracy 1 , loss 32.195\n",
            "step 26300, train accuracy 0.2 , loss 37.9015\n",
            "step 26400, train accuracy 0.95 , loss 9.61416\n",
            "step 26500, train accuracy 1 , loss 5.94262\n",
            "step 26600, train accuracy 0.95 , loss 33.4464\n",
            "step 26700, train accuracy 0.4 , loss 7.68155\n",
            "step 26800, train accuracy 0 , loss 5.5949\n",
            "step 26900, train accuracy 0 , loss 4.45637\n",
            "step 27000, train accuracy 0 , loss 27.7014\n",
            "step 27100, train accuracy 0.15 , loss 6.90343\n",
            "step 27200, train accuracy 0 , loss 10.0408\n",
            "step 27300, train accuracy 0.25 , loss 3.97945\n",
            "step 27400, train accuracy 0.25 , loss 5.00533\n",
            "step 27500, train accuracy 0.5 , loss 16.027\n",
            "step 27600, train accuracy 0.95 , loss 12.2965\n",
            "step 27700, train accuracy 0.95 , loss 9.98246\n",
            "step 27800, train accuracy 0.8 , loss 11.9463\n",
            "step 27900, train accuracy 0 , loss 49.9799\n",
            "step 28000, train accuracy 0.85 , loss 4.68512\n",
            "step 28100, train accuracy 0.95 , loss 14.3948\n",
            "step 28200, train accuracy 0.75 , loss 5.91321\n",
            "step 28300, train accuracy 0.9 , loss 9.7912\n",
            "step 28400, train accuracy 0.95 , loss 12.4914\n",
            "step 28500, train accuracy 0.35 , loss 6.08156\n",
            "step 28600, train accuracy 0 , loss 34.4986\n",
            "step 28700, train accuracy 1 , loss 1.92684\n",
            "step 28800, train accuracy 0.95 , loss 5.73291\n",
            "step 28900, train accuracy 0.95 , loss 19.0115\n",
            "step 29000, train accuracy 0.75 , loss 6.641\n",
            "step 29100, train accuracy 0.65 , loss 7.49696\n",
            "step 29200, train accuracy 1 , loss 3.82073\n",
            "step 29300, train accuracy 1 , loss 22.1121\n",
            "step 29400, train accuracy 0.75 , loss 10.5309\n",
            "step 29500, train accuracy 1 , loss 13.406\n",
            "step 29600, train accuracy 0.9 , loss 6.01159\n",
            "step 29700, train accuracy 1 , loss 18.2792\n",
            "step 29800, train accuracy 0.6 , loss 9.80871\n",
            "step 29900, train accuracy 0.8 , loss 7.00572\n",
            "step 30000, train accuracy 0 , loss 1.13169\n",
            "step 30100, train accuracy 0 , loss 31.2881\n",
            "step 30200, train accuracy 1 , loss 10.2251\n",
            "step 30300, train accuracy 0.45 , loss 22.1227\n",
            "step 30400, train accuracy 0.85 , loss 7.42458\n",
            "step 30500, train accuracy 0.95 , loss 15.7771\n",
            "step 30600, train accuracy 0.45 , loss 10.1303\n",
            "step 30700, train accuracy 1 , loss 3.5552\n",
            "step 30800, train accuracy 1 , loss 23.4144\n",
            "step 30900, train accuracy 0.85 , loss 13.8331\n",
            "step 31000, train accuracy 1 , loss 14.7119\n",
            "step 31100, train accuracy 1 , loss 8.09996\n",
            "step 31200, train accuracy 1 , loss 13.6229\n",
            "step 31300, train accuracy 0.8 , loss 10.5414\n",
            "step 31400, train accuracy 0 , loss 20.6038\n",
            "step 31500, train accuracy 0.85 , loss 6.87997\n",
            "step 31600, train accuracy 0.45 , loss 5.49549\n",
            "step 31700, train accuracy 0.15 , loss 3.86118\n",
            "step 31800, train accuracy 0 , loss 11.8548\n",
            "step 31900, train accuracy 0 , loss 4.03033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 32000, train accuracy 0 , loss 2.97706\n",
            "step 32100, train accuracy 0 , loss 14.7248\n",
            "step 32200, train accuracy 0.05 , loss 5.38193\n",
            "step 32300, train accuracy 0 , loss 19.8964\n",
            "step 32400, train accuracy 1 , loss 13.3844\n",
            "step 32500, train accuracy 0 , loss 22.5102\n",
            "step 32600, train accuracy 1 , loss 12.0821\n",
            "step 32700, train accuracy 0.75 , loss 9.07271\n",
            "step 32800, train accuracy 0 , loss 21.2662\n",
            "step 32900, train accuracy 1 , loss 4.04138\n",
            "step 33000, train accuracy 1 , loss 14.7076\n",
            "step 33100, train accuracy 0 , loss 20.0013\n",
            "step 33200, train accuracy 0.8 , loss 6.64015\n",
            "step 33300, train accuracy 1 , loss 4.30874\n",
            "step 33400, train accuracy 1 , loss 4.93872\n",
            "step 33500, train accuracy 1 , loss 2.14776\n",
            "step 33600, train accuracy 1 , loss 1.13331\n",
            "step 33700, train accuracy 1 , loss 2.34311\n",
            "step 33800, train accuracy 1 , loss 1.40912\n",
            "step 33900, train accuracy 1 , loss 21.2182\n",
            "step 34000, train accuracy 0.15 , loss 6.03259\n",
            "step 34100, train accuracy 0 , loss 20.3438\n",
            "step 34200, train accuracy 1 , loss 3.90969\n",
            "step 34300, train accuracy 1 , loss 2.46897\n",
            "step 34400, train accuracy 1 , loss 18.8026\n",
            "step 34500, train accuracy 0 , loss 4.31362\n",
            "step 34600, train accuracy 0 , loss 3.51011\n",
            "step 34700, train accuracy 0 , loss 17.6209\n",
            "step 34800, train accuracy 1 , loss 12.4107\n",
            "step 34900, train accuracy 0 , loss 14.8925\n",
            "step 35000, train accuracy 1 , loss 5.15755\n",
            "step 35100, train accuracy 1 , loss 21.2904\n",
            "step 35200, train accuracy 0 , loss 3.65235\n",
            "step 35300, train accuracy 0 , loss 2.31585\n",
            "step 35400, train accuracy 0 , loss 22.0204\n",
            "step 35500, train accuracy 1 , loss 4.08595\n",
            "step 35600, train accuracy 1 , loss 3.79516\n",
            "step 35700, train accuracy 1 , loss 1.82627\n",
            "step 35800, train accuracy 1 , loss 1.86549\n",
            "step 35900, train accuracy 1 , loss 23.4268\n",
            "step 36000, train accuracy 0 , loss 6.02949\n",
            "step 36100, train accuracy 1 , loss 16.7911\n",
            "step 36200, train accuracy 0 , loss 12.1264\n",
            "step 36300, train accuracy 0 , loss 9.34988\n",
            "step 36400, train accuracy 0.1 , loss 4.73995\n",
            "step 36500, train accuracy 0 , loss 16.5283\n",
            "step 36600, train accuracy 0 , loss 10.7408\n",
            "step 36700, train accuracy 1 , loss 9.08308\n",
            "step 36800, train accuracy 1 , loss 2.62222\n",
            "step 36900, train accuracy 1 , loss 15.1966\n",
            "step 37000, train accuracy 0.9 , loss 11.9389\n",
            "step 37100, train accuracy 0 , loss 5.73665\n",
            "step 37200, train accuracy 0 , loss 17.626\n",
            "step 37300, train accuracy 0 , loss 5.28896\n",
            "step 37400, train accuracy 0 , loss 10.3437\n",
            "step 37500, train accuracy 0.05 , loss 12.3982\n",
            "step 37600, train accuracy 1 , loss 5.37361\n",
            "step 37700, train accuracy 1 , loss 4.77469\n",
            "step 37800, train accuracy 1 , loss 2.25823\n",
            "step 37900, train accuracy 1 , loss 19.765\n",
            "step 38000, train accuracy 0 , loss 17.6014\n",
            "step 38100, train accuracy 0.05 , loss 7.37209\n",
            "step 38200, train accuracy 0 , loss 10.1525\n",
            "step 38300, train accuracy 0 , loss 13.4688\n",
            "step 38400, train accuracy 1 , loss 6.57337\n",
            "step 38500, train accuracy 1 , loss 14.5528\n",
            "step 38600, train accuracy 0 , loss 23.2338\n",
            "step 38700, train accuracy 0 , loss 10.1521\n",
            "step 38800, train accuracy 0 , loss 16.7022\n",
            "step 38900, train accuracy 0.7 , loss 3.82018\n",
            "step 39000, train accuracy 1 , loss 3.95891\n",
            "step 39100, train accuracy 1 , loss 25.9404\n",
            "step 39200, train accuracy 0 , loss 19.7299\n",
            "step 39300, train accuracy 0 , loss 4.85164\n",
            "step 39400, train accuracy 0 , loss 12.0094\n",
            "step 39500, train accuracy 0 , loss 4.43063\n",
            "step 39600, train accuracy 0 , loss 19.7461\n",
            "step 39700, train accuracy 0 , loss 4.93451\n",
            "step 39800, train accuracy 0 , loss 28.8455\n",
            "step 39900, train accuracy 1 , loss 15.2138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "step 40000, train accuracy 0 , loss 18.0646\n",
            "step 40100, train accuracy 0 , loss 8.99203\n",
            "step 40200, train accuracy 1 , loss 13.3478\n",
            "step 40300, train accuracy 0 , loss 7.08108\n",
            "step 40400, train accuracy 0 , loss 13.0485\n",
            "step 40500, train accuracy 0 , loss 6.10743\n",
            "step 40600, train accuracy 0 , loss 4.91344\n",
            "step 40700, train accuracy 0 , loss 17.8259\n",
            "step 40800, train accuracy 1 , loss 9.695\n",
            "step 40900, train accuracy 0 , loss 15.5202\n",
            "step 41000, train accuracy 1 , loss 4.12751\n",
            "step 41100, train accuracy 1 , loss 2.69297\n",
            "step 41200, train accuracy 1 , loss 21.8873\n",
            "step 41300, train accuracy 0 , loss 15.8676\n",
            "step 41400, train accuracy 0 , loss 5.80953\n",
            "step 41500, train accuracy 0 , loss 3.54557\n",
            "step 41600, train accuracy 0 , loss 8.21063\n",
            "step 41700, train accuracy 0 , loss 14.0074\n",
            "step 41800, train accuracy 0 , loss 10.0266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-93b0fd08c208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-93b0fd08c208>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "VMXyhdWUm7Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32360516-64ca-4cad-e4d9-2b3e6b7eb460"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  wang_data.csv\twang_data_test.csv\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NQTlklhDm8Ny",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}